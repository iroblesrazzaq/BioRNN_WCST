{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np; np.set_printoptions(precision=4); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=4); seed = 1; torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import itertools\n",
    "import random; random.seed(0)\n",
    "import scipy\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from textwrap import wrap\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.linalg import subspace_angles\n",
    "\n",
    "\n",
    "from functions import *\n",
    "\n",
    "print(torch.__version__)\n",
    "print(sys.version)\n",
    "                \n",
    "%matplotlib inline\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True) \n",
    "torch.backends.cudnn.deterministic = True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participation_ratio(lambdas):\n",
    "    \"\"\" compute the participation ratio from a list of eigenvalues \"\"\"\n",
    "    \n",
    "    sum_of_squares = 0\n",
    "    square_of_sum = 0\n",
    "    \n",
    "    for l in lambdas:\n",
    "        sum_of_squares += l**2\n",
    "        square_of_sum += l\n",
    "    \n",
    "    pr = square_of_sum**2/sum_of_squares\n",
    "    \n",
    "    return pr\n",
    "\n",
    "\n",
    "\n",
    "def compute_subspace(activity, d='pr'):\n",
    "    \"\"\" compute the subspace from a collection of neural trajectories\n",
    "        activity: (n_trials*n_timesteps) * n_neurons\n",
    "        d: # of dimensions for the subspace. Default: 'pr' (use the participation ratio) \n",
    "        \n",
    "        return: \n",
    "        subspace - n_dimensions * n_embedded_dimsneions\n",
    "        exp_var_ratio - explained variance ratio\n",
    "    \"\"\"\n",
    "    if d!='pr':\n",
    "        pca = PCA(n_components=d)\n",
    "        pca.fit(activity)\n",
    "        subspace = pca.components_\n",
    "        exp_var_ratio = pca.explained_variance_ratio_\n",
    "        n_dim = d\n",
    "    elif d=='pr':\n",
    "        pca = PCA(n_components=activity.shape[-1])\n",
    "        pca.fit(activity)\n",
    "        exp_var_ratio = pca.explained_variance_ratio_\n",
    "        pr = int(np.round(participation_ratio(exp_var_ratio)))\n",
    "        subspace = pca.components_[:pr]\n",
    "        exp_var_ratio = exp_var_ratio[:pr]\n",
    "        n_dim = pr\n",
    "        \n",
    "    return subspace, exp_var_ratio, n_dim\n",
    "\n",
    "\n",
    "def normalize_along_row(x):\n",
    "    \"\"\" normalize the rows of x \"\"\"\n",
    "    \n",
    "    y = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        y[i, :] = x[i, :]/np.sqrt(np.linalg.norm(x[i, :], ord=2))\n",
    "        \n",
    "    return y\n",
    "\n",
    "\n",
    "def remove_pane_and_grid_3d(ax):\n",
    "    \"\"\" remove the pane color and grid of a 3d plot \"\"\"\n",
    "    \n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for figure 6c, d (principal angel between subspaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "d = 'pr'    # number of dimensions for each subspace\n",
    "\n",
    "model_dir = ''\n",
    "test_data_dir = ''\n",
    "\n",
    "for model_name in sorted(os.listdir(model_dir)):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # load model\n",
    "        path_to_file = model_dir+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "\n",
    "            \n",
    "        # load data\n",
    "        with open(test_data_dir+model_name+'_testdata_noiseless_no_current_matrix', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        if mean_perf<0.8 or mean_perf_rule<0.8:\n",
    "            print('low performing model ({}/{})'.format(mean_perf, mean_perf_rule))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "\n",
    "        # group trials\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        stable_trs = rule1_trs_stable + rule2_trs_stable\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # obtain different subspaces\n",
    "        # generate subspaces\n",
    "        neuron_used = list(model.rnn.cg_idx['sr_esoma']) + list(model.rnn.cg_idx['sr_pv']) + list(model.rnn.cg_idx['sr_sst']) + list(model.rnn.cg_idx['sr_vip'])\n",
    "        time_used_rule = np.arange(hp_task_test['trial_history_start']//hp_test['dt'], hp_task_test['center_card_on']//hp_test['dt'])    # use the inter-trial epoch\n",
    "        time_used_choice = np.arange(hp_task_test['resp_start']//hp_test['dt'], hp_task_test['resp_end']//hp_test['dt'])\n",
    "        \n",
    "        ## rule 1 subspace\n",
    "        rnn_activity_sm_rule1 = rnn_activity[rule1_trs_stable, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "        rnn_activity_sm_rule1_flat = rnn_activity_sm_rule1.reshape(rnn_activity_sm_rule1.shape[0]*rnn_activity_sm_rule1.shape[1], rnn_activity_sm_rule1.shape[-1])\n",
    "        subspace_rule1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule1_flat, d=d)\n",
    "        \n",
    "        ## rule 2 subspace\n",
    "        rnn_activity_sm_rule2 = rnn_activity[rule2_trs_stable, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "        rnn_activity_sm_rule2_flat = rnn_activity_sm_rule2.reshape(rnn_activity_sm_rule2.shape[0]*rnn_activity_sm_rule2.shape[1], rnn_activity_sm_rule2.shape[-1])\n",
    "        subspace_rule2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule2_flat, d=d)\n",
    "        \n",
    "        ## choice 1 subspace\n",
    "        rnn_activity_sm_c1 = rnn_activity[c1_trs_stable, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "        rnn_activity_sm_c1_flat = rnn_activity_sm_c1.reshape(rnn_activity_sm_c1.shape[0]*rnn_activity_sm_c1.shape[1], rnn_activity_sm_c1.shape[-1])\n",
    "        subspace_c1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c1_flat, d=d)\n",
    "        \n",
    "        ## choice 2 subspace\n",
    "        rnn_activity_sm_c2 = rnn_activity[c2_trs_stable, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "        rnn_activity_sm_c2_flat = rnn_activity_sm_c2.reshape(rnn_activity_sm_c2.shape[0]*rnn_activity_sm_c2.shape[1], rnn_activity_sm_c2.shape[-1])\n",
    "        subspace_c2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c2_flat, d=d)\n",
    "        \n",
    "        ## choice 3 subspace\n",
    "        rnn_activity_sm_c3 = rnn_activity[c3_trs_stable, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "        rnn_activity_sm_c3_flat = rnn_activity_sm_c3.reshape(rnn_activity_sm_c3.shape[0]*rnn_activity_sm_c3.shape[1], rnn_activity_sm_c3.shape[-1])\n",
    "        subspace_c3, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c3_flat, d=d)\n",
    "        \n",
    "        # rule subspace\n",
    "        rnn_activity_rule = rnn_activity[stable_trs, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "        rnn_activity_rule_flat = rnn_activity_rule.reshape(rnn_activity_rule.shape[0]*rnn_activity_rule.shape[1], rnn_activity_rule.shape[-1])\n",
    "        subspace_rule, exp_var_ratio, n_dim = compute_subspace(rnn_activity_rule_flat, d=d)\n",
    "        \n",
    "        # choice subspace\n",
    "        rnn_activity_choice = rnn_activity[stable_trs, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "        rnn_activity_choice_flat = rnn_activity_choice.reshape(rnn_activity_choice.shape[0]*rnn_activity_choice.shape[1], rnn_activity_choice.shape[-1])\n",
    "        subspace_choice, exp_var_ratio, n_dim = compute_subspace(rnn_activity_choice_flat, d=d)\n",
    "        \n",
    "        # compute angle between subspaces\n",
    "        angle_rule_subspace = np.rad2deg(subspace_angles(subspace_rule1.T, subspace_rule2.T)[0])\n",
    "        angle_choice12_subspace = np.rad2deg(subspace_angles(subspace_c1.T, subspace_c2.T)[0])\n",
    "        angle_choice13_subspace = np.rad2deg(subspace_angles(subspace_c1.T, subspace_c3.T)[0])\n",
    "        angle_choice23_subspace = np.rad2deg(subspace_angles(subspace_c2.T, subspace_c3.T)[0])\n",
    "        angle_choice_subspace_avg = np.mean([angle_choice12_subspace, angle_choice13_subspace, angle_choice23_subspace])\n",
    "        angle_rule_choice = np.rad2deg(subspace_angles(subspace_rule.T, subspace_choice.T)[0])\n",
    "        \n",
    "        \n",
    "        # Do the same for shuffled data\n",
    "        angle_rules_shuffle = []\n",
    "        angle_choices_shuffle = []\n",
    "        angle_rule_choices_shuffle = []\n",
    "        \n",
    "        for _ in range(100):\n",
    "            # generate shuffled trials\n",
    "            rule_trs_stable = rule1_trs_stable + rule2_trs_stable\n",
    "            rule1_trs_split1 = np.random.choice(rule1_trs_stable, size=len(rule1_trs_stable)//2, replace=False)\n",
    "            rule1_trs_split2 = [tr for tr in rule1_trs_stable if tr not in rule1_trs_split1]\n",
    "            rule2_trs_split1 = np.random.choice(rule2_trs_stable, size=len(rule2_trs_stable)//2, replace=False)\n",
    "            rule2_trs_split2 = [tr for tr in rule2_trs_stable if tr not in rule2_trs_split1]\n",
    "            \n",
    "            choice_trs_stable = c1_trs_stable + c2_trs_stable + c3_trs_stable\n",
    "            c1_trs_split1 = np.random.choice(c1_trs_stable, size=len(c1_trs_stable)//2, replace=False)\n",
    "            c1_trs_split2 = [tr for tr in c1_trs_stable if tr not in c1_trs_split1]\n",
    "            c2_trs_split1 = np.random.choice(c2_trs_stable, size=len(c2_trs_stable)//2, replace=False)\n",
    "            c2_trs_split2 = [tr for tr in c2_trs_stable if tr not in c2_trs_split1]\n",
    "            c3_trs_split1 = np.random.choice(c3_trs_stable, size=len(c3_trs_stable)//2, replace=False)\n",
    "            c3_trs_split2 = [tr for tr in c3_trs_stable if tr not in c3_trs_split1]\n",
    "\n",
    "            \n",
    "            # generate subspaces\n",
    "        \n",
    "            ## rule 1 subspace\n",
    "            rnn_activity_sm_rule1_split1 = rnn_activity[rule1_trs_split1, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule1_split1 = rnn_activity_sm_rule1_split1.reshape(rnn_activity_sm_rule1_split1.shape[0]*rnn_activity_sm_rule1_split1.shape[1], rnn_activity_sm_rule1_split1.shape[-1])\n",
    "            subspace_rule1_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule1_split1, d=d)\n",
    "\n",
    "            rnn_activity_sm_rule1_split2 = rnn_activity[rule1_trs_split2, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule1_split2 = rnn_activity_sm_rule1_split2.reshape(rnn_activity_sm_rule1_split2.shape[0]*rnn_activity_sm_rule1_split2.shape[1], rnn_activity_sm_rule1_split2.shape[-1])\n",
    "            subspace_rule1_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule1_split2, d=d)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            ## rule 2 subspace\n",
    "            rnn_activity_sm_rule2_split1 = rnn_activity[rule2_trs_split1, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule2_split1 = rnn_activity_sm_rule2_split1.reshape(rnn_activity_sm_rule2_split1.shape[0]*rnn_activity_sm_rule2_split1.shape[1], rnn_activity_sm_rule2_split1.shape[-1])\n",
    "            subspace_rule2_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule2_split1, d=d)\n",
    "\n",
    "            rnn_activity_sm_rule2_split2 = rnn_activity[rule2_trs_split2, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule2_split2 = rnn_activity_sm_rule2_split2.reshape(rnn_activity_sm_rule2_split2.shape[0]*rnn_activity_sm_rule2_split2.shape[1], rnn_activity_sm_rule2_split2.shape[-1])\n",
    "            subspace_rule2_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule2_split2, d=d)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            ## choice 1 subspace\n",
    "            rnn_activity_sm_c1_split1 = rnn_activity[c1_trs_split1, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_c1_split1 = rnn_activity_sm_c1_split1.reshape(rnn_activity_sm_c1_split1.shape[0]*rnn_activity_sm_c1_split1.shape[1], rnn_activity_sm_c1_split1.shape[-1])\n",
    "            subspace_c1_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c1_split1, d=d)\n",
    "\n",
    "            rnn_activity_sm_c1_split2 = rnn_activity[c1_trs_split2, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_c1_split2 = rnn_activity_sm_c1_split2.reshape(rnn_activity_sm_c1_split2.shape[0]*rnn_activity_sm_c1_split2.shape[1], rnn_activity_sm_c1_split2.shape[-1])\n",
    "            subspace_c1_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c1_split2, d=d)\n",
    "\n",
    "                \n",
    "            ## choice 2 subspace\n",
    "            rnn_activity_sm_c2_split1 = rnn_activity[c2_trs_split1, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_c2_split1 = rnn_activity_sm_c2_split1.reshape(rnn_activity_sm_c2_split1.shape[0]*rnn_activity_sm_c2_split1.shape[1], rnn_activity_sm_c2_split1.shape[-1])\n",
    "            subspace_c2_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c2_split1, d=d)\n",
    " \n",
    "            rnn_activity_sm_c2_split2 = rnn_activity[c2_trs_split2, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_c2_split2 = rnn_activity_sm_c2_split2.reshape(rnn_activity_sm_c2_split2.shape[0]*rnn_activity_sm_c2_split2.shape[1], rnn_activity_sm_c2_split2.shape[-1])\n",
    "            subspace_c2_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c2_split2, d=d)\n",
    "\n",
    "\n",
    "                \n",
    "            ## choice 3 subspace\n",
    "            rnn_activity_sm_c3_split1 = rnn_activity[c3_trs_split1, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_c3_split1 = rnn_activity_sm_c3_split1.reshape(rnn_activity_sm_c3_split1.shape[0]*rnn_activity_sm_c3_split1.shape[1], rnn_activity_sm_c3_split1.shape[-1])\n",
    "            subspace_c3_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c3_split1, d=d)\n",
    "\n",
    "            rnn_activity_sm_c3_split2 = rnn_activity[c3_trs_split2, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_c3_split2 = rnn_activity_sm_c3_split2.reshape(rnn_activity_sm_c3_split2.shape[0]*rnn_activity_sm_c3_split2.shape[1], rnn_activity_sm_c3_split2.shape[-1])\n",
    "            subspace_c3_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_c3_split2, d=d)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            ## rule and choice subspaces\n",
    "            rule_trs_stable = rule1_trs_stable + rule2_trs_stable\n",
    "            rule_trs_split1 = np.random.choice(rule_trs_stable, size=len(rule_trs_stable)//2, replace=False)\n",
    "            rule_trs_split2 = [tr for tr in rule_trs_stable if tr not in rule_trs_split1]\n",
    "            \n",
    "            choice_trs_stable = c1_trs_stable + c2_trs_stable + c3_trs_stable\n",
    "            choice_trs_split1 = np.random.choice(choice_trs_stable, size=len(choice_trs_stable)//2, replace=False)\n",
    "            choice_trs_split2 = [tr for tr in choice_trs_stable if tr not in choice_trs_split1]\n",
    "            \n",
    "            rnn_activity_rule_split1 = rnn_activity[rule_trs_split1, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_rule_split2 = rnn_activity[rule_trs_split2, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_rule_split1_flat = rnn_activity_rule_split1.reshape(rnn_activity_rule_split1.shape[0]*rnn_activity_rule_split1.shape[1], rnn_activity_rule_split1.shape[-1])\n",
    "            rnn_activity_rule_split2_flat = rnn_activity_rule_split2.reshape(rnn_activity_rule_split2.shape[0]*rnn_activity_rule_split2.shape[1], rnn_activity_rule_split2.shape[-1])\n",
    "            \n",
    "            rnn_activity_choice_split1 = rnn_activity[choice_trs_split1, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_choice_split2 = rnn_activity[choice_trs_split2, :, 0, :][:, time_used_choice, :][:, :, neuron_used]\n",
    "            rnn_activity_choice_split1_flat = rnn_activity_choice_split1.reshape(rnn_activity_choice_split1.shape[0]*rnn_activity_choice_split1.shape[1], rnn_activity_choice_split1.shape[-1])\n",
    "            rnn_activity_choice_split2_flat = rnn_activity_choice_split2.reshape(rnn_activity_choice_split2.shape[0]*rnn_activity_choice_split2.shape[1], rnn_activity_choice_split2.shape[-1])\n",
    "            \n",
    "            subspace_rule_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_rule_split1_flat, d=d)\n",
    "            subspace_rule_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_rule_split2_flat, d=d)\n",
    "            subspace_choice_split1, exp_var_ratio, n_dim = compute_subspace(rnn_activity_choice_split1_flat, d=d)\n",
    "            subspace_choice_split2, exp_var_ratio, n_dim = compute_subspace(rnn_activity_choice_split2_flat, d=d)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            # compute angle between subspaces\n",
    "            angle_rule1_subspace_shuffle = np.rad2deg(subspace_angles(subspace_rule1_split1.T, subspace_rule1_split2.T)[0])\n",
    "            angle_rule2_subspace_shuffle = np.rad2deg(subspace_angles(subspace_rule2_split1.T, subspace_rule2_split2.T)[0])\n",
    "            angle_rule_subspace_shuffle = np.mean([angle_rule1_subspace_shuffle, angle_rule2_subspace_shuffle])\n",
    "            \n",
    "            angle_c1_subspace_shuffle = np.rad2deg(subspace_angles(subspace_c1_split1.T, subspace_c1_split2.T)[0])\n",
    "            angle_c2_subspace_shuffle = np.rad2deg(subspace_angles(subspace_c2_split1.T, subspace_c2_split2.T)[0])\n",
    "            angle_c3_subspace_shuffle = np.rad2deg(subspace_angles(subspace_c3_split1.T, subspace_c3_split2.T)[0])\n",
    "            angle_choice_subspace_avg_shuffle = np.mean([angle_c1_subspace_shuffle, angle_c2_subspace_shuffle, angle_c3_subspace_shuffle])\n",
    "            \n",
    "            angle_rule_subspace_shuffle = np.rad2deg(subspace_angles(subspace_rule_split1.T, subspace_rule_split2.T )[0])\n",
    "            angle_choice_subspace_shuffle = np.rad2deg(subspace_angles(subspace_choice_split1.T, subspace_choice_split2.T)[0])\n",
    "            angle_rule_choice_subspace_shuffle = np.mean([angle_rule_subspace_shuffle, angle_choice_subspace_shuffle])\n",
    "\n",
    "            # append to the list\n",
    "            angle_rules_shuffle.append(angle_rule_subspace_shuffle)\n",
    "            angle_choices_shuffle.append(angle_choice_subspace_avg_shuffle)\n",
    "            angle_rule_choices_shuffle.append(angle_rule_choice_subspace_shuffle)\n",
    "            \n",
    "\n",
    "        # collect data\n",
    "        all_data[model_name] = {\n",
    "                               'model_name': model_name,\n",
    "                               'hp': hp_test,\n",
    "                               'angle_rule_subspace': angle_rule_subspace,\n",
    "                               'angle_rule_subspace_shuffle': angle_rules_shuffle,\n",
    "                               'angle_choice_subspace_avg': angle_choice_subspace_avg,\n",
    "                               'angle_choice_subspace_avg_shuffle': angle_choices_shuffle,\n",
    "                               'angle_rule_choice': angle_rule_choice,\n",
    "                               'angle_rule_choice_shuffle': angle_rule_choices_shuffle\n",
    "                               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_rules_all_models = []\n",
    "angle_rules_all_models_shuffle = []\n",
    "angle_choices_all_models = []\n",
    "angle_choices_all_models_shuffle = []\n",
    "angle_rule_choice_all_models = []\n",
    "angle_rule_choice_all_models_shuffle = []\n",
    "\n",
    "model_list = list(all_data.keys())\n",
    "for model in model_list:\n",
    "    if all_data[model]['hp']['dend_nonlinearity']!='subtractive':    # here, subselect models with either divisive or subtractive nonlinearity\n",
    "        continue\n",
    "    angle_rules_all_models.append(all_data[model]['angle_rule_subspace'])\n",
    "    angle_rules_all_models_shuffle.extend(all_data[model]['angle_rule_subspace_shuffle'])\n",
    "    angle_choices_all_models.append(all_data[model]['angle_choice_subspace_avg'])\n",
    "    angle_choices_all_models_shuffle.extend(all_data[model]['angle_choice_subspace_avg_shuffle'])\n",
    "    angle_rule_choice_all_models.append(all_data[model]['angle_rule_choice'])\n",
    "    angle_rule_choice_all_models_shuffle.extend(all_data[model]['angle_rule_choice_shuffle'])\n",
    "\n",
    "\n",
    "# subspace angle compare to shuffled data\n",
    "fig, ax = plt.subplots(1, 2, figsize=[10, 3])\n",
    "bins=np.arange(0, 90, 1)\n",
    "ax[0].set_title('principle angle between rule subspaces')\n",
    "ax[1].set_title('principle angle between choice subspaces')\n",
    "\n",
    "ax[0].hist(angle_rules_all_models, color='k', density=True, bins=bins)\n",
    "ax[0].hist(angle_rules_all_models_shuffle, color='gray', alpha=0.5, density=True, bins=bins)\n",
    "\n",
    "ax[1].hist(angle_choices_all_models, color='k', density=True, bins=bins)\n",
    "ax[1].hist(angle_choices_all_models_shuffle, color='gray', alpha=0.5, density=True, bins=bins)\n",
    "\n",
    "for i in range(2):\n",
    "    make_pretty_axes(ax[i])\n",
    "    ax[i].set_xlim([0, 90])\n",
    "    ax[i].set_xticks([0, 90])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7f: the principal angle when SST/PV neurons are inhibited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = 'pr'\n",
    "\n",
    "model_dir = ''\n",
    "test_data_dir = ''\n",
    "\n",
    "for model_name in sorted(os.listdir(model_dir)):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name)\n",
    "        \n",
    "        if model_name not in list(all_data.keys()):\n",
    "            print('model perf is low, excluded in previous analysis, skip')\n",
    "            continue\n",
    "            \n",
    "        # load model\n",
    "        path_to_file = model_dir+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "        \n",
    "        if hp_test['dend_nonlinearity'] not in ['subtractive', 'divisive_2']:\n",
    "            print('filtered')\n",
    "            continue\n",
    "            \n",
    "        # subspace with SST silenced\n",
    "        with open(test_data_dir+model_name+'_testdata_silenceSRSST_withnoise_no_current_matrix', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "    \n",
    "        if np.isnan(rnn_activity).any():\n",
    "            print('NAN in rnn_activity')\n",
    "            angle_rule_subspace_nosst = np.nan\n",
    "        else:\n",
    "            # group trials\n",
    "            trial_labels = label_trials_wcst(test_data=test_data)\n",
    "            rule1_trs = trial_labels['rule1_trs']\n",
    "            rule2_trs = trial_labels['rule2_trs']\n",
    "            c1_trs = trial_labels['c1_trs']\n",
    "            c2_trs = trial_labels['c2_trs']\n",
    "            c3_trs = trial_labels['c3_trs']\n",
    "            error_trials = trial_labels['error_trials']\n",
    "\n",
    "            # generate subspaces\n",
    "            neuron_used = list(model.rnn.cg_idx['sr_esoma']) + list(model.rnn.cg_idx['sr_pv']) + list(model.rnn.cg_idx['sr_sst']) + list(model.rnn.cg_idx['sr_vip'])\n",
    "            time_used_rule = np.arange(hp_task_test['trial_history_start']//hp_test['dt'], hp_task_test['center_card_on']//hp_test['dt'])\n",
    "            time_used_choice = np.arange(hp_task_test['resp_start']//hp_test['dt'], hp_task_test['resp_end']//hp_test['dt'])\n",
    "\n",
    "            ## rule 1 subspace\n",
    "            rnn_activity_sm_rule1 = rnn_activity[rule1_trs, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule1_flat = rnn_activity_sm_rule1.reshape(rnn_activity_sm_rule1.shape[0]*rnn_activity_sm_rule1.shape[1], rnn_activity_sm_rule1.shape[-1])\n",
    "            subspace_rule1_nosst, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule1_flat, d=d)\n",
    "\n",
    "            ## rule 2 subspace\n",
    "            rnn_activity_sm_rule2 = rnn_activity[rule2_trs, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule2_flat = rnn_activity_sm_rule2.reshape(rnn_activity_sm_rule2.shape[0]*rnn_activity_sm_rule2.shape[1], rnn_activity_sm_rule2.shape[-1])\n",
    "            subspace_rule2_nosst, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule2_flat, d=d)\n",
    "        \n",
    "            # compute angle between subspaces\n",
    "            angle_rule_subspace_nosst = np.rad2deg(subspace_angles(subspace_rule1_nosst.T, subspace_rule2_nosst.T)[0])\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        # subspace with PV silenced\n",
    "        with open(test_data_dir+model_name+'_testdata_silenceSRPV_noiseless_no_current_matrix', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "    \n",
    "        if np.isnan(rnn_activity).any():\n",
    "            print('NAN in rnn_activity')\n",
    "            angle_rule_subspace_nopv = np.nan\n",
    "        else:\n",
    "            # group trials\n",
    "            trial_labels = label_trials_wcst(test_data=test_data)\n",
    "            rule1_trs = trial_labels['rule1_trs']\n",
    "            rule2_trs = trial_labels['rule2_trs']\n",
    "            c1_trs = trial_labels['c1_trs']\n",
    "            c2_trs = trial_labels['c2_trs']\n",
    "            c3_trs = trial_labels['c3_trs']\n",
    "            error_trials = trial_labels['error_trials']\n",
    "\n",
    "            # generate subspaces\n",
    "            neuron_used = list(model.rnn.cg_idx['sr_esoma']) + list(model.rnn.cg_idx['sr_pv']) + list(model.rnn.cg_idx['sr_sst']) + list(model.rnn.cg_idx['sr_vip'])\n",
    "            time_used_rule = np.arange(hp_task_test['trial_history_start']//hp_test['dt'], hp_task_test['center_card_on']//hp_test['dt'])\n",
    "            time_used_choice = np.arange(hp_task_test['resp_start']//hp_test['dt'], hp_task_test['resp_end']//hp_test['dt'])\n",
    "\n",
    "            ## rule 1 subspace\n",
    "            rnn_activity_sm_rule1 = rnn_activity[rule1_trs, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule1_flat = rnn_activity_sm_rule1.reshape(rnn_activity_sm_rule1.shape[0]*rnn_activity_sm_rule1.shape[1], rnn_activity_sm_rule1.shape[-1])\n",
    "            subspace_rule1_nopv, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule1_flat, d=d)\n",
    "            \n",
    "            ## rule 2 subspace\n",
    "            rnn_activity_sm_rule2 = rnn_activity[rule2_trs, :, 0, :][:, time_used_rule, :][:, :, neuron_used]\n",
    "            rnn_activity_sm_rule2_flat = rnn_activity_sm_rule2.reshape(rnn_activity_sm_rule2.shape[0]*rnn_activity_sm_rule2.shape[1], rnn_activity_sm_rule2.shape[-1])\n",
    "            subspace_rule2_nopv, exp_var_ratio, n_dim = compute_subspace(rnn_activity_sm_rule2_flat, d=d)\n",
    "\n",
    "            # compute angle between subspaces\n",
    "            angle_rule_subspace_nopv = np.rad2deg(subspace_angles(subspace_rule1_nopv.T, subspace_rule2_nopv.T)[0])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        # add to the data dict\n",
    "        all_data[model_name]['angle_rule_subspace_nopv'] = angle_rule_subspace_nopv\n",
    "        all_data[model_name]['angle_rule_subspace_nosst'] = angle_rule_subspace_nosst\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "# subspace angle when silencing SST neurons\n",
    "fig, ax = plt.subplots(1, 1, figsize=[3, 4])\n",
    "ax.set_title('principle angle between\\n rule subspaces')\n",
    "\n",
    "model_list = list(all_data.keys())\n",
    "\n",
    "for model in model_list:\n",
    "    if all_data[model]['hp']['dend_nonlinearity']!='divisive_2':\n",
    "        continue\n",
    "    if ~np.isnan(all_data[model]['angle_rule_subspace_nosst']):\n",
    "        ax[0].plot([0, 1], [all_data[model]['angle_rule_subspace'], all_data[model]['angle_rule_subspace_nosst']], color='k', alpha=0.5, marker='o')\n",
    "make_pretty_axes(ax)\n",
    "ax.set_ylim([0, 90])\n",
    "ax.set_yticks([0, 90])\n",
    "ax.set_xlim([-0.5, 1.5])\n",
    "ax.set_xticks([0, 1], ['intact', 'silenced \\nSST'])\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
