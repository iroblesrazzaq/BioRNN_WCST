{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np; np.set_printoptions(precision=2); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=2)\n",
    "seed = 1\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib \n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as pl\n",
    "from mpltern.ternary.datasets import get_scatter_points\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import itertools \n",
    "import random; random.seed(0)\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import scipy; from scipy import stats; from scipy.stats import wilcoxon\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../two_module_rnn/code\")\n",
    "os.chdir('/home/yl4317/Documents/two_module_rnn/code')\n",
    "# from model_working import *\n",
    "from functions import *\n",
    "\n",
    "os.chdir('/home/yl4317/Documents/two_module_rnn/code/code_for_figs')\n",
    "\n",
    "print(torch.__version__)\n",
    "print(sys.version)\n",
    "                \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data: input and output weight of the sensorimotor module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name+'\\n')\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "        # for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation']:\n",
    "        #     print(key, hp_test[key])\n",
    "\n",
    "        # load test data\n",
    "        with open('/scratch/yl4317/two_module_rnn/saved_testdata/'+model_name+'_testdata_noiseless_no_current_matrix', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_test_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        if mean_test_perf<=0.8:\n",
    "            print('perf too low ({}), pass\\n'.format(mean_test_perf))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "        \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "        error_trials = trial_labels['error_trials']\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                         rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                         rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "                                         resp_trs_stable = resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                         stims=test_data['stims'], error_trials=trial_labels['error_trials'], trial_labels=trial_labels)\n",
    "\n",
    "        # define neuron pools\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          rule_threshold=0, resp_threshold=0)\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        w_in_eff = model.rnn.effective_weight(w=model.rnn.w_in, mask=model.rnn.mask_in).detach().cpu().numpy()\n",
    "        all_data.append({'model': model, 'model_name': model_name, 'hp': hp_test, \n",
    "                         'n_sr_esoma': model.rnn.n['sr_esoma'], 'n_branches': model.rnn.n_branches, \n",
    "                         'w_in_eff': w_in_eff, 'subcg_sr_idx': subcg_sr_idx, 'all_sels': all_sels})\n",
    "\n",
    "with open('/home/yl4317/Documents/two_module_rnn/processed_data/conn_bias_sm_w_in.pickle', 'wb') as handle:\n",
    "        pickle.dump(all_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Elapsed time: {}s'.format(time.time()-start))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5c: bias in the input weight, one example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/home/yl4317/Documents/two_module_rnn/processed_data/conn_bias_sm_w_in.pickle', 'rb') as handle:\n",
    "    all_data = pickle.load(handle)\n",
    "\n",
    "\n",
    "data_fig5c = {'big': [], 'small': []}\n",
    "\n",
    "for data in all_data:\n",
    "    if data['model_name'] != 'success_2023-05-10-14-28-42_wcst_106_sparsity0':    # this is the example model\n",
    "        continue\n",
    "    w_in_larges = []\n",
    "    w_in_large_refs = []\n",
    "    w_in_large_tests = []\n",
    "    w_in_smalls = []\n",
    "    for r in [1, 2]:\n",
    "        for choice in [1, 2, 3]:\n",
    "            for card in ['(0, 0)', '(1, 0)', '(0, 1)', '(1, 1)']:\n",
    "                neuron_id_rule = data['subcg_sr_idx']['rule{}_sr_esoma'.format(r)]\n",
    "                neuron_id_choice = data['subcg_sr_idx']['respc{}_sr_esoma'.format(choice)]\n",
    "                neuron_id_refcard = data['subcg_sr_idx']['ref_card{}_sr_esoma'.format(card)]\n",
    "                neuron_id = [n for n in neuron_id_rule if (n in neuron_id_choice and n in neuron_id_refcard)]    # all neurons that prefer a given combination of rule, choice and reference card (and therefore feature)        \n",
    "                # print('rule {}, choice {}, card {}\\nneuron_id {}'.format(r, choice, card, neuron_id))\n",
    "                if (r==1 and (card=='(0, 0)' or card=='(0, 1)')) or (r==2 and (card=='(0, 0)' or card=='(1, 0)')):\n",
    "                    feature_id = 0    # this neuron prefers when the matching feature is blue or circle\n",
    "                else:\n",
    "                    feature_id = 1    # this neuron prefers when the matching feature is red or square \n",
    "#                 input_neuron_id_large = [2*(r-1) + feature_id, 4+4*(choice-1) + 2*(r-1) + feature_id]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                input_neuron_id_large_ref = 2*(r-1) + feature_id\n",
    "                input_neuron_id_large_test = 4+4*(choice-1) + 2*(r-1) + feature_id\n",
    "                input_neuron_id_large = [input_neuron_id_large_ref, input_neuron_id_large_test]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                input_neuron_id_small = [i for i in range(data['w_in_eff'].shape[0]) if i not in input_neuron_id_large]\n",
    "                for n in neuron_id:\n",
    "                    dend_id = [n + (b+1)*data['n_sr_esoma'] for b in range(data['n_branches'])]    # the dendritic indices\n",
    "                    w_in_large = data['w_in_eff'][np.ix_(input_neuron_id_large, dend_id)]\n",
    "                    w_in_small = data['w_in_eff'][np.ix_(input_neuron_id_small, dend_id)]\n",
    "                    w_in_large_ref = data['w_in_eff'][input_neuron_id_large_ref, dend_id]\n",
    "                    w_in_large_test = data['w_in_eff'][input_neuron_id_large_test, dend_id]\n",
    "                    \n",
    "                    w_in_larges.append(np.mean(w_in_large))\n",
    "                    w_in_smalls.append(np.mean(w_in_small))\n",
    "                    w_in_large_refs.append(np.mean(w_in_large_ref))\n",
    "                    w_in_large_tests.append(np.mean(w_in_large_test))\n",
    "                    \n",
    "    #=== plotting ===#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(len(w_in_larges)):\n",
    "        ax.plot([w_in_larges[i], w_in_smalls[i]], marker='o', markersize=10, alpha=0.5, color='k')\n",
    "    y = [w_in_larges, w_in_smalls]\n",
    "    \n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_ylabel(r'Input weight', fontsize=20)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nfeature', 'Non-preferred\\nfeature'], rotation=0, fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    # fig.savefig('/home/yl4317/Documents/two_module_rnn/figs/w_in_sm_example.pdf')\n",
    "    \n",
    "    # statistical test\n",
    "    t, p = scipy.stats.ttest_ind(y[0], y[1], alternative='greater')\n",
    "    print('t={}, p-value={}, n={}'.format(t, p, len(y[0])))\n",
    "\n",
    "    # save source data\n",
    "    data_fig5c['big'] = w_in_larges\n",
    "    data_fig5c['small'] = w_in_smalls\n",
    "    # pd.DataFrame.from_dict(data=data_fig5c, orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/fig5c_w_in_example.csv', header=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary figure 9a, b: across all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_suppfig9ab = {'subtractive': {}, 'divisive_2': {}}\n",
    "for key in data_suppfig9.keys():\n",
    "    data_suppfig9ab[key] = {'big': [], 'small': []}\n",
    "    \n",
    "for dend_nonlinear in ['subtractive', 'divisive_2']:\n",
    "    w_in_large_all_models = []\n",
    "    w_in_large_ref_all_models = []\n",
    "    w_in_large_test_all_models = []\n",
    "    w_in_small_all_models = []\n",
    "    for data in all_data:\n",
    "        if data['hp']['dend_nonlinearity'] != dend_nonlinear: \n",
    "            continue\n",
    "        w_in_larges = []\n",
    "        w_in_large_refs = []\n",
    "        w_in_large_tests = []\n",
    "        w_in_smalls = []\n",
    "        for r in [1, 2]:\n",
    "            for choice in [1, 2, 3]:\n",
    "                for card in ['(0, 0)', '(1, 0)', '(0, 1)', '(1, 1)']:\n",
    "                    neuron_id_rule = data['subcg_sr_idx']['rule{}_sr_esoma'.format(r)]\n",
    "                    neuron_id_choice = data['subcg_sr_idx']['respc{}_sr_esoma'.format(choice)]\n",
    "                    neuron_id_refcard = data['subcg_sr_idx']['ref_card{}_sr_esoma'.format(card)]\n",
    "                    neuron_id = [n for n in neuron_id_rule if (n in neuron_id_choice and n in neuron_id_refcard)]    # all neurons that prefer a given combination of rule, choice and reference card (and therefore feature)        \n",
    "                    if (r==1 and (card=='(0, 0)' or card=='(0, 1)')) or (r==2 and (card=='(0, 0)' or card=='(1, 0)')):\n",
    "                        feature_id = 0    # this neuron prefers when the matching feature is blue or circle\n",
    "                    else:\n",
    "                        feature_id = 1    # this neuron prefers when the matching feature is red or square \n",
    "                    input_neuron_id_large_ref = 2*(r-1) + feature_id\n",
    "                    input_neuron_id_large_test = 4+4*(choice-1) + 2*(r-1) + feature_id\n",
    "                    input_neuron_id_large = [input_neuron_id_large_ref, input_neuron_id_large_test]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                    input_neuron_id_small = [i for i in range(data['w_in_eff'].shape[0]) if i not in input_neuron_id_large]\n",
    "                    for n in neuron_id:\n",
    "                        dend_id = [n + (b+1)*data['n_sr_esoma'] for b in range(data['n_branches'])]    # the dendritic indices\n",
    "                        w_in_large = data['w_in_eff'][np.ix_(input_neuron_id_large, dend_id)]\n",
    "                        w_in_small = data['w_in_eff'][np.ix_(input_neuron_id_small, dend_id)]\n",
    "                        w_in_large_ref = data['w_in_eff'][input_neuron_id_large_ref, dend_id]\n",
    "                        w_in_large_test = data['w_in_eff'][input_neuron_id_large_test, dend_id]\n",
    "                        \n",
    "                        w_in_larges.append(np.mean(w_in_large))\n",
    "                        w_in_smalls.append(np.mean(w_in_small))\n",
    "                        w_in_large_refs.append(np.mean(w_in_large_ref))\n",
    "                        w_in_large_tests.append(np.mean(w_in_large_test))\n",
    "    \n",
    "        w_in_large_all_models.extend(w_in_larges)\n",
    "        w_in_large_ref_all_models.extend(w_in_large_refs)\n",
    "        w_in_large_test_all_models.extend(w_in_large_tests)\n",
    "        w_in_small_all_models.extend(w_in_smalls)\n",
    "    \n",
    "    #=== plotting ===#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.suptitle(dend_nonlinear)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(len(w_in_large_all_models)):\n",
    "        ax.plot([w_in_large_all_models[i], w_in_small_all_models[i]], marker='o', markersize=10, alpha=0.1, color='k')\n",
    "    y = [w_in_large_all_models, w_in_small_all_models]\n",
    "    \n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_ylabel(r'Input weight', fontsize=20)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nfeature', 'Non-preferred\\nfeature'], rotation=0, fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    fig.savefig('/home/yl4317/Documents/two_module_rnn/figs/w_in_sm_allNetworks_{}.pdf'.format(dend_nonlinear))\n",
    "    \n",
    "    # statistical test\n",
    "    t, p = scipy.stats.ttest_ind(y[0], y[1], alternative='greater')\n",
    "    print('t={}, p-value={}, n={}'.format(t, p, len(y[0])))\n",
    "\n",
    "    # save source data\n",
    "    data_suppfig9ab[dend_nonlinear]['big'] = w_in_large_all_models\n",
    "    data_suppfig9ab[dend_nonlinear]['small'] = w_in_small_all_models\n",
    "    pd.DataFrame.from_dict(data=data_suppfig9ab[dend_nonlinear], orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/suppfig9ab_w_in_allNets_{}.csv'.format(dend_nonlinear), header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for output weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "all_data_wout = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name+'\\n')\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "\n",
    "        # load test data\n",
    "        with open('/scratch/yl4317/two_module_rnn/saved_testdata/'+model_name+'_testdata_noiseless_no_current_matrix', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_test_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        if mean_test_perf<=0.8:\n",
    "            print('perf too low ({}), pass\\n'.format(mean_test_perf))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "#         current_matrix = neural_data['current_matrix']\n",
    "        \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "        error_trials = trial_labels['error_trials']\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                         rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                         rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "                                         resp_trs_stable = resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                         stims=test_data['stims'], error_trials=trial_labels['error_trials'], trial_labels=trial_labels)\n",
    "\n",
    "        # define neuron pools\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          rule_threshold=0, resp_threshold=0)\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        w_out_eff = model.rnn.effective_weight(w=model.rnn.w_out, mask=model.mask_out).detach().cpu().numpy()\n",
    "\n",
    "        all_data_wout.append({\n",
    "                              'model': model, \n",
    "                              'model_name': model_name, \n",
    "                              'hp': hp_test, \n",
    "                              'w_out_eff': w_out_eff,\n",
    "                              'subcg_sr_idx': subcg_sr_idx\n",
    "                             })\n",
    "\n",
    "with open('/home/yl4317/Documents/two_module_rnn/processed_data/conn_bias_sm_w_out.pickle', 'wb') as handle:\n",
    "        pickle.dump(all_data_wout, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "print('Elapsed time: {}s'.format(time.time()-start))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5d: w_out for an example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/yl4317/Documents/two_module_rnn/processed_data/conn_bias_sm_w_out.pickle', 'rb') as handle:\n",
    "    all_data_wout = pickle.load(handle)\n",
    "\n",
    "data_fig5d = {'big': [], 'small': []}\n",
    "\n",
    "for data in all_data_wout:\n",
    "    if data['model_name'] != 'success_2023-05-10-14-28-42_wcst_136_sparsity0':    # this is the example model shown in the paper\n",
    "        continue\n",
    "    print(data['model_name'])\n",
    "    wout_pref = []\n",
    "    wout_nonpref = []\n",
    "    wout = data['w_out_eff']\n",
    "    for resp in ['c1', 'c2', 'c3']:\n",
    "        neuron_idx = data['subcg_sr_idx']['resp{}_sr_esoma'.format(resp)]\n",
    "        # print('resp {}, neuron_idx {}'.format(resp, neuron_idx))\n",
    "        if resp=='c1':\n",
    "            wout_idx_pref, wout_idx_nonpref = 0, [1, 2]\n",
    "        elif resp=='c2':\n",
    "            wout_idx_pref, wout_idx_nonpref = 1, [0, 2]\n",
    "        elif resp=='c3':\n",
    "            wout_idx_pref, wout_idx_nonpref = 2, [0, 1]\n",
    "        wout_pref.extend(wout[neuron_idx, wout_idx_pref])\n",
    "        wout_nonpref.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "\n",
    "    #===== plotting =====#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.plot([0, 1], [wout_pref, wout_nonpref], color='k', marker='o', alpha=0.5)\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "    ax.set_ylabel('Readout weight', fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# statistical test\n",
    "t, p = scipy.stats.ttest_ind(wout_pref, wout_nonpref, alternative='greater')\n",
    "print('t={}, p-value={}, n={}'.format(t, p, len(wout_pref)))\n",
    "\n",
    "# save figure\n",
    "# fig.savefig('/home/yl4317/Documents/two_module_rnn/figs/w_out_example.pdf')\n",
    "\n",
    "# collect source data\n",
    "data_fig5d['big'].extend(wout_pref)\n",
    "data_fig5d['small'].extend(wout_nonpref)\n",
    "# pd.DataFrame.from_dict(data=data_fig5d, orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/fig5d.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figure 9c, d: w_out, across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_suppfig19cd = {'subtractive': {}, 'divisive_2': {}}\n",
    "for key in data_suppfig19cd.keys():\n",
    "    data_suppfig19cd[key] = {'big': [], 'small': []}\n",
    "\n",
    "\n",
    "for dend_nonlinear in ['subtractive', 'divisive_2']:\n",
    "    wout_pref_all = []\n",
    "    wout_nonpref_all = []\n",
    "    for data in all_data_wout:\n",
    "        if data['hp']['dend_nonlinearity'] != dend_nonlinear:   \n",
    "            continue\n",
    "        # wout_pref = []\n",
    "        # wout_nonpref = []\n",
    "        wout = data['w_out_eff']\n",
    "        for resp in ['c1', 'c2', 'c3']:\n",
    "            neuron_idx = data['subcg_sr_idx']['resp{}_sr_esoma'.format(resp)]\n",
    "            if resp=='c1':\n",
    "                wout_idx_pref, wout_idx_nonpref = 0, [1, 2]\n",
    "            elif resp=='c2':\n",
    "                wout_idx_pref, wout_idx_nonpref = 1, [0, 2]\n",
    "            elif resp=='c3':\n",
    "                wout_idx_pref, wout_idx_nonpref = 2, [0, 1]\n",
    "            wout_pref_all.extend(wout[neuron_idx, wout_idx_pref])\n",
    "            wout_nonpref_all.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "            \n",
    "    #===== plotting =====#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.plot([0, 1], [wout_pref_all, wout_nonpref_all], color='k', marker='o', alpha=0.1)\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "    ax.set_ylabel('Readout weight', fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # statistical test\n",
    "    t, p = scipy.stats.ttest_ind(wout_pref_all, wout_nonpref_all, alternative='greater')\n",
    "    print('t={}, p-value={}, n={}'.format(t, p, len(wout_pref_all)))\n",
    "\n",
    "    # save figure\n",
    "    fig.savefig('/home/yl4317/Documents/two_module_rnn/figs/w_out_allNets_{}.pdf'.format(dend_nonlinear))\n",
    "    \n",
    "    # collect source data\n",
    "    data_suppfig19cd[dend_nonlinear]['big'].extend(wout_pref_all)\n",
    "    data_suppfig19cd[dend_nonlinear]['small'].extend(wout_nonpref_all)\n",
    "    pd.DataFrame.from_dict(data=data_suppfig19cd[dend_nonlinear], orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/suppfig19cd_wout_{}.csv'.format(dend_nonlinear), header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 6e-g Compute the connectivity bias between the sensorimotor populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# whether SR E soma are selective for both rule and response\n",
    "start = time.time()\n",
    "plot = False\n",
    "\n",
    "conn_bias_sr_all_models = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "#     if 'success_2022-09-19-13-52-05_wcst_15_longer_iti_5dend_nonlineaerities' in model_name:\n",
    "#     if ('2022-10-24' in model_name) and 'success' in model_name:\n",
    "        print(model_name)\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file, model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "#         print(hp_test['dend_nonlinearity'])\n",
    "        # add filters here\n",
    "        if hp_test['dt']!=10:\n",
    "            continue\n",
    "        if hp_test['dend_nonlinearity'] not in ['subtractive', 'divisive_2']:\n",
    "            continue\n",
    "#         if hp_test['sparse_srsst_to_sredend']!=0:\n",
    "#             continue\n",
    "#         if hp_test['no_pfcesoma_to_srsst']==True:\n",
    "#             continue\n",
    "        \n",
    "        for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation']:\n",
    "            print(key, hp_test[key])\n",
    "            \n",
    "        # make noiseless\n",
    "#         model.rnn.network_noise = 0\n",
    "#         hp_test['input_noise_perceptual'] = 0\n",
    "#         hp_test['input_noise_rule'] = 0\n",
    "        \n",
    "        # generate some neural data\n",
    "#         neural_data = generate_neural_data_test(model=model, n_trials_test=100, switch_every_test=10, n_switches=5, to_plot=False, hp_test=hp_test, hp_task_test=hp_task_test)\n",
    "        with open('/scratch/yl4317/two_module_rnn/saved_testdata/{}'.format(model_name+'_testdata_noiseless_no_current_matrix'), 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        if mean_perf<0.8 or mean_perf_rule<0.8:\n",
    "            print('low performing model ({}/{})'.format(mean_perf, mean_perf_rule))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "\n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        resp_trs_stable = {'c1': trial_labels['c1_trs_stable'], 'c2': trial_labels['c2_trs_stable'], 'c3': trial_labels['c3_trs_stable']}\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                     rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                     rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error = trial_labels['rule2_trs_after_error'],\n",
    "                                     resp_trs_stable=resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                     stims=test_data['stims'], error_trials=trial_labels['error_trials'], trial_labels=trial_labels)\n",
    "        rule_sel_used= all_sels['rule_normalized_activity']    \n",
    "        \n",
    "        \n",
    "        resp_sel_normalized = all_sels['resp_normalized']\n",
    "        rule_sel_normalized = all_sels['rule_normalized_activity']\n",
    "\n",
    "        # subregions\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], \n",
    "                                          ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=trial_labels['rule1_trs_stable'], \n",
    "                                          rule2_trs_stable=trial_labels['rule2_trs_stable'], \n",
    "                                          rule_threshold=0.0, resp_threshold=0.0)\n",
    "    \n",
    "        # plot connectivity between subpopulations\n",
    "        w_rec_eff = model.rnn.effective_weight(w=model.rnn.w_rec, mask=model.rnn.mask, w_fix=model.rnn.w_fix).detach().cpu().numpy()\n",
    "        if plot==True:\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=['rule1_sr_esoma', 'rule2_sr_esoma', 'rule1_sr_pv', 'rule2_sr_pv'], subcg_to_plot_receiver=['rule1_sr_esoma', 'rule2_sr_esoma', 'rule1_sr_pv', 'rule2_sr_pv'])\n",
    "#             _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=['rule1_sr_pv', 'rule2_sr_pv'], subcg_to_plot_receiver=['rule1_sr_pv', 'rule2_sr_pv'])\n",
    "#             resp_pops = ['{}_{}'.format(resp, cell) for (resp, cell) in itertools.product(*[['respc1', 'respc2', 'respc3'], ['sr_esoma', 'sr_pv']])]\n",
    "            resp_pops = ['respc1_sr_esoma', 'respc2_sr_esoma', 'respc3_sr_esoma', 'respc1_sr_pv', 'respc2_sr_pv', 'respc3_sr_pv']\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=resp_pops, subcg_to_plot_receiver=resp_pops)\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=['respc1_sr_pv', 'respc2_sr_pv', 'respc3_sr_pv'], subcg_to_plot_receiver=['respc1_sr_pv', 'respc2_sr_pv', 'respc3_sr_pv'])\n",
    "#             ref_card_pops = ['ref_card(0, 0)_sr_esoma', 'ref_card(0, 1)_sr_esoma', 'ref_card(1, 0)_sr_esoma', 'ref_card(1, 1)_sr_esoma', \n",
    "#                              'ref_card(0, 0)_sr_pv', 'ref_card(0, 1)_sr_pv', 'ref_card(1, 0)_sr_pv', 'ref_card(1, 1)_sr_pv', ]\n",
    "#             _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=ref_card_pops, subcg_to_plot_receiver=ref_card_pops)\n",
    "            shared_feature_pops_color = ['blue_sr_esoma', 'red_sr_esoma', 'blue_sr_pv', 'red_sr_pv']\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=shared_feature_pops_color, subcg_to_plot_receiver=shared_feature_pops_color)\n",
    "            shared_feature_pops_shape = ['circle_sr_esoma', 'triangle_sr_esoma', 'circle_sr_pv', 'triangle_sr_pv']\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=shared_feature_pops_shape, subcg_to_plot_receiver=shared_feature_pops_shape)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # compute connectivity bias for rule\n",
    "        conn_bias_rulee_rulee = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule1_sr_esoma'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule2_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule2_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule1_sr_esoma'])])\n",
    "        conn_bias_rulee_rulepv = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule1_sr_pv'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule2_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule2_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule1_sr_pv'])])\n",
    "        conn_bias_rulepv_rulee = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule2_sr_esoma'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule1_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule1_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule2_sr_esoma'])])\n",
    "        conn_bias_rulepv_rulee = -conn_bias_rulepv_rulee\n",
    "        conn_bias_rulepv_rulepv = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule2_sr_pv'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule1_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule1_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule2_sr_pv'])])\n",
    "        conn_bias_rulepv_rulepv = -conn_bias_rulepv_rulepv\n",
    "        \n",
    "                     \n",
    "            \n",
    "            \n",
    "        # connectivity bias based on neurons preferring different responses              \n",
    "        conn = {}\n",
    "        conn[('resp_sr_esoma', 'resp_sr_esoma')] = {}\n",
    "        conn[('resp_sr_esoma', 'resp_sr_pv')] = {}\n",
    "        conn[('resp_sr_pv', 'resp_sr_esoma')] = {}\n",
    "        conn[('resp_sr_pv', 'resp_sr_pv')] = {}\n",
    "        for key in conn.keys():\n",
    "            for x in ['same', 'cross']:\n",
    "                conn[key][x] = []\n",
    "        \n",
    "        for resp1 in ['c1', 'c2', 'c3']:\n",
    "            for resp2 in ['c1', 'c2', 'c3']:\n",
    "                if resp1==resp2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('resp_{}'.format(sender), 'resp_{}'.format(receiver))]['same'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['resp{}_{}'.format(resp1, sender)], subcg_sr_idx['resp{}_{}'.format(resp2, receiver)])]))\n",
    "                elif resp1!=resp2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('resp_{}'.format(sender), 'resp_{}'.format(receiver))]['cross'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['resp{}_{}'.format(resp1, sender)], subcg_sr_idx['resp{}_{}'.format(resp2, receiver)])]))     \n",
    "                        \n",
    "        conn_bias_respe_respe = np.mean(conn[('resp_sr_esoma', 'resp_sr_esoma')]['same']) - np.mean(conn[('resp_sr_esoma', 'resp_sr_esoma')]['cross'])\n",
    "        conn_bias_respe_resppv = np.mean(conn[('resp_sr_esoma', 'resp_sr_pv')]['same']) - np.mean(conn[('resp_sr_esoma', 'resp_sr_pv')]['cross'])\n",
    "        conn_bias_resppv_respe = - (np.mean(conn[('resp_sr_pv', 'resp_sr_esoma')]['cross']) - np.mean(conn[('resp_sr_pv', 'resp_sr_esoma')]['same']))\n",
    "        conn_bias_resppv_resppv = - (np.mean(conn[('resp_sr_pv', 'resp_sr_pv')]['cross']) - np.mean(conn[('resp_sr_pv', 'resp_sr_pv')]['same']))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # connectivity bias based on neurons preferring different reference cards\n",
    "        conn = {}\n",
    "        conn[('ref_card_sr_esoma', 'ref_card_sr_esoma')] = {}\n",
    "        conn[('ref_card_sr_esoma', 'ref_card_sr_pv')] = {}\n",
    "        conn[('ref_card_sr_pv', 'ref_card_sr_esoma')] = {}\n",
    "        conn[('ref_card_sr_pv', 'ref_card_sr_pv')] = {}\n",
    "        for key in conn.keys():\n",
    "            for x in ['same', 'cross']:\n",
    "                conn[key][x] = []\n",
    "            \n",
    "        for ref_card1 in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "            for ref_card2 in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "                if ref_card1==ref_card2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('ref_card_{}'.format(sender), 'ref_card_{}'.format(receiver))]['same'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['ref_card{}_{}'.format(ref_card1, sender)], subcg_sr_idx['ref_card{}_{}'.format(ref_card2, receiver)])]))\n",
    "                elif ref_card1!=ref_card2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('ref_card_{}'.format(sender), 'ref_card_{}'.format(receiver))]['cross'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['ref_card{}_{}'.format(ref_card1, sender)], subcg_sr_idx['ref_card{}_{}'.format(ref_card2, receiver)])]))     \n",
    "                        \n",
    "        conn_bias_ref_card_e_ref_card_e = np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_esoma')]['same']) - np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_esoma')]['cross'])\n",
    "        conn_bias_ref_card_e_ref_card_pv = np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_pv')]['same']) - np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_pv')]['cross'])\n",
    "        conn_bias_ref_card_pv_ref_card_e = - (np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_esoma')]['cross']) - np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_esoma')]['same']))\n",
    "        conn_bias_ref_card_pv_ref_card_pv = - (np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_pv')]['cross']) - np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_pv')]['same']))\n",
    "        \n",
    "        \n",
    "        # connectivity bias based on neurons preferring different reference cards\n",
    "        conn = {}\n",
    "        conn[('shared_feature_sr_esoma', 'shared_feature_sr_esoma')] = {}\n",
    "        conn[('shared_feature_sr_esoma', 'shared_feature_sr_pv')] = {}\n",
    "        conn[('shared_feature_sr_pv', 'shared_feature_sr_esoma')] = {}\n",
    "        conn[('shared_feature_sr_pv', 'shared_feature_sr_pv')] = {}\n",
    "        for key in conn.keys():\n",
    "            for x in ['same', 'cross']:\n",
    "                conn[key][x] = []\n",
    "        \n",
    "        shared_features = ['blue', 'red', 'circle', 'triangle']\n",
    "        for f1 in shared_features:\n",
    "            for f2 in shared_features:\n",
    "                for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                    mean_weight = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['{}_{}'.format(f1, sender)], subcg_sr_idx['{}_{}'.format(f2, receiver)])])\n",
    "                    if f1==f2:\n",
    "                        conn[('shared_feature_{}'.format(sender), 'shared_feature_{}'.format(receiver))]['same'].append(mean_weight)\n",
    "                    elif f1!=f2 and shared_features.index(f1)//2 == shared_features.index(f2)//2:    # do not include for example f1=blue and f2=square\n",
    "                        conn[('shared_feature_{}'.format(sender), 'shared_feature_{}'.format(receiver))]['cross'].append(mean_weight)     \n",
    "                        \n",
    "        conn_bias_shared_feature_e_e = np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_esoma')]['same']) - np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_esoma')]['cross'])\n",
    "        conn_bias_shared_feature_e_pv = np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_pv')]['same']) - np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_pv')]['cross'])\n",
    "        conn_bias_shared_feature_pv_e = - (np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_esoma')]['cross']) - np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_esoma')]['same']))\n",
    "        conn_bias_shared_feature_pv_pv = - (np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_pv')]['cross']) - np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_pv')]['same']))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        conn_bias_sr_all_models.append({'model': model_name, \n",
    "                                        'hp': hp_test,\n",
    "                                        'bias_ruleesoma_ruleesoma': conn_bias_rulee_rulee, \n",
    "                                        'bias_ruleesoma_rulepv': conn_bias_rulee_rulepv, \n",
    "                                        'bias_rulepv_ruleesoma': conn_bias_rulepv_rulee, \n",
    "                                        'bias_rulepv_rulepv': conn_bias_rulepv_rulepv,\n",
    "                                        'bias_respesoma_respesoma': conn_bias_respe_respe, \n",
    "                                        'bias_respesoma_resppv': conn_bias_respe_resppv, \n",
    "                                        'bias_resppv_respesoma': conn_bias_resppv_respe, \n",
    "                                        'bias_resppv_resppv': conn_bias_resppv_resppv,\n",
    "                                        'bias_ref_card_esoma_ref_card_esoma': conn_bias_ref_card_e_ref_card_e, \n",
    "                                        'bias_ref_card_esoma_ref_card_pv': conn_bias_ref_card_e_ref_card_pv, \n",
    "                                        'bias_ref_card_pv_ref_card_esoma': conn_bias_ref_card_pv_ref_card_e, \n",
    "                                        'bias_ref_card_pv_ref_card_pv': conn_bias_ref_card_pv_ref_card_pv,\n",
    "                                        'bias_shared_feature_esoma_esoma': conn_bias_shared_feature_e_e, \n",
    "                                        'bias_shared_feature_esoma_pv': conn_bias_shared_feature_e_pv, \n",
    "                                        'bias_shared_feature_pv_esoma': conn_bias_shared_feature_pv_e, \n",
    "                                        'bias_shared_feature_pv_pv': conn_bias_shared_feature_pv_pv,\n",
    "                                       })\n",
    "        # print('biases: {}'.format(conn_bias_sr_all_models[-1][2:]))\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_fig7e = {'exc_exc': [], 'exc_pv': [], 'pv_exc': [], 'pv_pv': []}    # connectivity biases between rule-selective populations\n",
    "data_fig7f = {'exc_exc': [], 'exc_pv': [], 'pv_exc': [], 'pv_pv': []}    # connectivity biases between response location-selective populations\n",
    "data_fig7g = {'exc_exc': [], 'exc_pv': [], 'pv_exc': [], 'pv_pv': []}    # connectivity biases between shared feature-selective populations\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['subtractive']:\n",
    "        continue\n",
    "    data = list(x.values())[2:6]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "#     if 'success_2022-09-19-13-52-05_wcst_15_longer_iti_5dend_nonlineaerities' not in x['hp']['save_name']:\n",
    "#         continue\n",
    "\n",
    "    data_fig7e['exc_exc'].append(data[0])\n",
    "    data_fig7e['exc_pv'].append(data[1])\n",
    "    data_fig7e['pv_exc'].append(data[2])\n",
    "    data_fig7e['pv_pv'].append(data[3])\n",
    "\n",
    "    \n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'rule E $\\rightarrow$ rule E', r'rule E $\\rightarrow$ rule PV', r'rule PV $\\rightarrow$ rule E', r'rule PV $\\rightarrow$ rule PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['subtractive']:\n",
    "        continue\n",
    "    data = list(x.values())[6:10]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "#     if 'success_2022-09-19-13-52-05_wcst_15_longer_iti_5dend_nonlineaerities' not in x['hp']['save_name']:\n",
    "#         continue\n",
    "\n",
    "\n",
    "    data_fig7f['exc_exc'].append(data[0])\n",
    "    data_fig7f['exc_pv'].append(data[1])\n",
    "    data_fig7f['pv_exc'].append(data[2])\n",
    "    data_fig7f['pv_pv'].append(data[3])\n",
    "\n",
    "    \n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'resp E $\\rightarrow$ resp E', r'resp E $\\rightarrow$ resp PV', r'resp PV $\\rightarrow$ resp E', r'resp PV $\\rightarrow$ resp PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['subtractive']:\n",
    "        continue\n",
    "    data = list(x.values())[10:14]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "#     if 'success_2022-09-19-13-52-05_wcst_15_longer_iti_5dend_nonlineaerities' not in x['hp']['save_name']:\n",
    "#         continue\n",
    "    \n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'ref card E $\\rightarrow$ ref card E', r'ref card E $\\rightarrow$ ref card PV', r'ref card PV $\\rightarrow$ ref card E', r'ref card PV $\\rightarrow$ ref card PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['subtractive']:\n",
    "        continue\n",
    "    data = list(x.values())[14:18]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "#     if 'success_2022-09-19-13-52-05_wcst_15_longer_iti_5dend_nonlineaerities' not in x['hp']['save_name']:\n",
    "#         continue\n",
    "\n",
    "\n",
    "    data_fig7g['exc_exc'].append(data[0])\n",
    "    data_fig7g['exc_pv'].append(data[1])\n",
    "    data_fig7g['pv_exc'].append(data[2])\n",
    "    data_fig7g['pv_pv'].append(data[3])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'shared feature E $\\rightarrow$ E', r'shared feature E $\\rightarrow$ PV', r'shared feature PV $\\rightarrow$ E', r'shared feature PV $\\rightarrow$ PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "pd.DataFrame.from_dict(data=data_fig7e, orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/fig7e.csv', header=False)\n",
    "pd.DataFrame.from_dict(data=data_fig7f, orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/fig7f.csv', header=False)\n",
    "pd.DataFrame.from_dict(data=data_fig7g, orient='index').to_csv('/home/yl4317/Documents/two_module_rnn/source_data/fig7g.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# plt.rc('font', size=12)\n",
    "\n",
    "# all_data_wout = []\n",
    "\n",
    "# for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "#     if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "#         print(model_name+'\\n')\n",
    "        \n",
    "# #         # load model\n",
    "#         path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "#         with HiddenPrints():\n",
    "#             model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "# #         if hp_test['dt']!=10:\n",
    "# #             print('pass\\n')\n",
    "# #             continue\n",
    "# #         if len(hp_test['cell_group_list'])==2:\n",
    "# #             print('pass\\n')\n",
    "# #             continue\n",
    "# #         if hp_test['dend_nonlinearity'] not in ['v2', 'subtract_v2', 'old_v2', 'subtract_v3', 'v3', 'v2_std']:\n",
    "# #             continue\n",
    "# #         if hp_test['no_pfcesoma_to_srsst']==True:\n",
    "# #             continue\n",
    "# #         if hp_test['sparse_srsst_to_sredend']!=0:\n",
    "# #             continue\n",
    "        \n",
    "#         for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation']:\n",
    "#             print(key, hp_test[key])\n",
    "            \n",
    "#         # make noiseless\n",
    "# #         model.rnn.network_noise = 0\n",
    "# #         hp_test['input_noise_perceptual'] = 0\n",
    "# #         hp_test['input_noise_rule'] = 0\n",
    "        \n",
    "#         # generate some neural data\n",
    "# #         neural_data = generate_neural_data_test(model=model, n_trials_test=100, switch_every_test=10, to_plot=False, hp_test=hp_test, hp_task_test=hp_task_test, compute_current=False)\n",
    "#         with open('/scratch/yl4317/two_module_rnn/saved_testdata/'+model_name+'_testdata_noiseless_no_current_matrix', 'rb') as f:\n",
    "#             neural_data = pickle.load(f)\n",
    "#         test_data = neural_data['test_data']\n",
    "#         mean_test_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "#         if mean_test_perf<=0.8:\n",
    "#             print('perf too low ({}), pass\\n'.format(mean_test_perf))\n",
    "#             continue\n",
    "#         rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "# #         current_matrix = neural_data['current_matrix']\n",
    "        \n",
    "#         # generate trial labels\n",
    "#         trial_labels = label_trials_wcst(test_data=test_data)\n",
    "#         rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "#         rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "#         rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "#         rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "#         c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "#         c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "#         c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "#         resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "#         error_trials = trial_labels['error_trials']\n",
    "        \n",
    "#         # compute cell selectivity\n",
    "#         all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "#                                          rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "#                                          rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "#                                          resp_trs_stable = resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "#                                          stims=test_data['stims'], error_trials=trial_labels['error_trials'])\n",
    "\n",
    "#         # define neuron pools\n",
    "#         subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "#                                           rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], ref_card_sel=all_sels['ref_card_normalized'],\n",
    "#                                           rule1_trs_stable=rule1_trs_stable, \n",
    "#                                           rule2_trs_stable=rule2_trs_stable, \n",
    "#                                           rule_threshold=0, resp_threshold=0)\n",
    "#         for subcg in subcg_sr_idx.keys():\n",
    "#             model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "#         w_out_eff = model.rnn.effective_weight(w=model.rnn.w_out, mask=model.mask_out).detach().cpu().numpy()\n",
    "\n",
    "#         all_data_wout.append({\n",
    "#                               'model': model, \n",
    "#                               'model_name': model_name, \n",
    "#                               'hp': hp_test, \n",
    "#                               'w_out_eff': w_out_eff,\n",
    "#                               'subcg_sr_idx': subcg_sr_idx\n",
    "#                              })\n",
    "                \n",
    "# print('Elapsed time: {}s'.format(time.time()-start))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wout_pref_all = []\n",
    "# wout_nonpref_all = []\n",
    "\n",
    "# for data in all_data_wout:\n",
    "#     if data['hp']['dend_nonlinearity']!='divisive_2':\n",
    "#         continue\n",
    "#     print(data['model_name'])\n",
    "#     wout_pref = []\n",
    "#     wout_nonpref = []\n",
    "#     wout = data['w_out_eff']\n",
    "#     for resp in ['c1', 'c2', 'c3']:\n",
    "#         neuron_idx = data['subcg_sr_idx']['resp{}_sr_esoma'.format(resp)]\n",
    "#         if resp=='c1':\n",
    "#             wout_idx_pref, wout_idx_nonpref = 0, [1, 2]\n",
    "#         elif resp=='c2':\n",
    "#             wout_idx_pref, wout_idx_nonpref = 1, [0, 2]\n",
    "#         elif resp=='c3':\n",
    "#             wout_idx_pref, wout_idx_nonpref = 2, [0, 1]\n",
    "#         wout_pref.extend(wout[neuron_idx, wout_idx_pref])\n",
    "#         wout_nonpref.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "#         wout_pref_all.extend(wout[neuron_idx, wout_idx_pref])\n",
    "#         wout_nonpref_all.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "        \n",
    "#     fig, ax = plt.subplots(figsize=[10,7])\n",
    "#     fig.patch.set_facecolor('white')\n",
    "#     ax.plot([0, 1], [wout_pref, wout_nonpref], color='k', marker='o', alpha=0.5)\n",
    "#     ax.set_xlim([-0.2, 1.2])\n",
    "#     ax.set_xticks([0, 1])\n",
    "#     ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "#     ax.set_ylabel('Readout weight', fontsize=20)\n",
    "#     make_pretty_axes(ax)\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "# print('all models')\n",
    "# fig, ax = plt.subplots(figsize=[7,7])\n",
    "# fig.patch.set_facecolor('white')\n",
    "# ax.plot([0, 1], [wout_pref_all, wout_nonpref_all], color='k', marker='o', alpha=0.02)\n",
    "# ax.set_xlim([-0.3, 1.3])\n",
    "# ax.set_xticks([0, 1])\n",
    "# ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "# ax.set_ylabel('Readout weight', fontsize=20)\n",
    "# make_pretty_axes(ax)\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
