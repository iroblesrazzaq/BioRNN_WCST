{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np; np.set_printoptions(precision=4); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=4)\n",
    "seed = 1\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt; plt.rc('font', size=12); \n",
    "import matplotlib \n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import itertools\n",
    "import random; random.seed(0)\n",
    "import scipy\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from textwrap import wrap\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# from model import *\n",
    "from functions import *\n",
    "\n",
    "                \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "all_data_branch_coding = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/model/directory/')):\n",
    "    if ('2023-05-01' in model_name or '2023-05-10' in model_name) and 'success' in model_name:\n",
    "        print(model_name)\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/model/directory/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "\n",
    "        # load test data\n",
    "        with open('/where/test/data/is/stored/{}_testdata_noiseless'.format(model_name), 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "        if np.isnan(rnn_activity).any():\n",
    "            print('NaN in rnn_activity, pass\\n')\n",
    "            continue\n",
    "        \n",
    "        mean_perf = np.mean(np.array(test_data['perfs']))\n",
    "        mean_perf_rule = np.mean(np.array(test_data['perf_rules']))\n",
    "        if mean_perf<=0.8 or mean_perf_rule<=0.8:\n",
    "            print('This model performance is low!! {}/{}\\n'.format(mean_perf, mean_perf_rule))\n",
    "            continue\n",
    "            \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        if len(trial_labels['rule1_trs_stable'])==0 or len(trial_labels['rule2_trs_stable'])==0:\n",
    "            print('no rule 1 or 2 trials, pass\\n')\n",
    "            continue\n",
    "        resp_trs_stable = {'c1': trial_labels['c1_trs_stable'], 'c2': trial_labels['c2_trs_stable'], 'c3': trial_labels['c3_trs_stable']}\n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                     rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                     rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error = trial_labels['rule2_trs_after_error'],\n",
    "                                     resp_trs_stable=resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                     stims=test_data['stims'], error_trials=trial_labels['error_trials'], trial_labels=trial_labels)\n",
    "        rule_sel_norm = all_sels['rule_normalized_activity']\n",
    "        rule_sel_unnorm = all_sels['rule_activity']\n",
    "        \n",
    "        ## analysis 1\n",
    "        dend1_idx = np.arange(model.rnn.cg_idx['sr_edend'][0], model.rnn.cg_idx['sr_edend'][0]+len(model.rnn.cg_idx['sr_esoma']))\n",
    "        dend2_idx = [n for n in model.rnn.cg_idx['sr_edend'] if n not in dend1_idx]\n",
    "        \n",
    "        \n",
    "        rule_sel_dend1_norm = [rule_sel_norm[n] for n in dend1_idx]\n",
    "        rule_sel_dend2_norm = [rule_sel_norm[n] for n in dend2_idx]\n",
    "        rule_sel_dend1_unnorm = [rule_sel_unnorm[n] for n in dend1_idx]\n",
    "        rule_sel_dend2_unnorm = [rule_sel_unnorm[n] for n in dend2_idx]\n",
    "        \n",
    "        mean_act = np.mean(rnn_activity, axis=(0,1,2))\n",
    "        \n",
    "        ## analysis 2\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=trial_labels['rule1_trs_stable'], \n",
    "                                          rule2_trs_stable=trial_labels['rule2_trs_stable'], \n",
    "                                          rule_threshold=0, resp_threshold=0)\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "        \n",
    "        mean_rule_sel_all_sm_esoma = np.mean([all_sels['rule_normalized_activity'][n] for n in model.rnn.cg_idx['sr_esoma']])\n",
    "        sr_esoma_rule_cell_idx = np.concatenate((model.rnn.cg_idx['subcg_sr_rule1_sr_esoma'], model.rnn.cg_idx['subcg_sr_rule2_sr_esoma']))\n",
    "        mean_rule_sel_all_sm_esoma_rule_cells = np.mean([all_sels['rule_normalized_activity'][n] for n in sr_esoma_rule_cell_idx])\n",
    "        \n",
    "        ## analysis 3, cosine similarity between the mean activity vector during the two rules\n",
    "        mean_state_rule1 = rnn_activity[trial_labels['rule1_trs_stable'], :, 0, :][:, :, model.rnn.cg_idx['sr_esoma']]\n",
    "        mean_state_rule1 = np.mean(mean_state_rule1, axis=(0, 1))\n",
    "        mean_state_rule2 = rnn_activity[trial_labels['rule2_trs_stable'], :, 0, :][:, :, model.rnn.cg_idx['sr_esoma']]\n",
    "        mean_state_rule2 = np.mean(mean_state_rule2, axis=(0, 1))\n",
    "        cosine = cosine_similarity(X=mean_state_rule1.reshape(1, -1), Y=mean_state_rule2.reshape(1, -1))\n",
    "        \n",
    "        all_data_branch_coding.append({'model': model, \n",
    "                                       'model_name': model_name, \n",
    "                                       'hp': hp_test, \n",
    "                                       'rule_sel_dend1_norm': rule_sel_dend1_norm, \n",
    "                                       'rule_sel_dend2_norm': rule_sel_dend2_norm, \n",
    "                                       'rule_sel_dend1_unnorm': rule_sel_dend1_unnorm, \n",
    "                                       'rule_sel_dend2_unnorm': rule_sel_dend2_unnorm, \n",
    "#                                        'rule_sel': rule_sel_used, \n",
    "                                       'act_rule1': all_sels['act_rule1'],\n",
    "                                       'act_rule2': all_sels['act_rule2'], \n",
    "                                       'mean_act': mean_act, \n",
    "                                       'all_sels': all_sels,\n",
    "#                                        'mean_rule_sel_all_sm_esoma': mean_rule_sel_all_sm_esoma,\n",
    "#                                        'mean_rule_sel_all_sm_esoma_rule_cells': mean_rule_sel_all_sm_esoma_rule_cells,\n",
    "#                                        'cosine': cosine,\n",
    "                                       'dend1_idx': dend1_idx,\n",
    "                                       'dend2_idx': dend2_idx,\n",
    "                                       'subcg_sr_idx': subcg_sr_idx})\n",
    "        \n",
    "print(time.time()-start)\n",
    "with open('all_data_branch_coding.pickle', 'wb') as f:\n",
    "    pickle.dump(all_data_branch_coding, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7b, c: rule selectivity of the two dendritic branches of the same neuron, for sparsity 0 and 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dend_nonlinears = sorted(list(set(x['hp']['dend_nonlinearity'] for x in all_data_branch_coding)))\n",
    "all_sparsitys = sorted(list(set(x['hp']['sparse_srsst_to_sredend'] for x in all_data_branch_coding)))\n",
    "for dend_nonlinear in ['subtractive']:\n",
    "    print(dend_nonlinear)\n",
    "    for sparsity in all_sparsitys:\n",
    "        fig, ax = plt.subplots(figsize=[7,7])\n",
    "        fig.patch.set_facecolor('white')\n",
    "        fig.suptitle('Rule selectivity for the two branches, \\nacross all models, {} {}'.format(sparsity, dend_nonlinear), fontsize=20)\n",
    "        ax.set_xlabel('Rule selectivity of \\none dendritic branch', fontsize=20)\n",
    "        ax.set_ylabel('Rule selectivity of \\nthe other dendritic branch', fontsize=20)\n",
    "        ax.set_xlim([-1, 1])\n",
    "        ax.set_ylim([-1, 1])\n",
    "        for x in all_data_branch_coding:\n",
    "            if x['hp']['sparse_srsst_to_sredend']!=sparsity or (x['hp']['dend_nonlinearity']!=dend_nonlinear):\n",
    "                continue\n",
    "            for n in range(70):\n",
    "                # do not plot dendrites that are inactive in both rules\n",
    "                dend1_idx = n+70    # id of one dendritic branch\n",
    "                dend2_idx = n+140    # the other branch\n",
    "                ax.scatter(x=x['rule_sel_dend1_norm'][n], y=x['rule_sel_dend2_norm'][n], s=30, color='k', alpha=1)\n",
    "                ax.axvline(x=0, linestyle='dotted', color='k')\n",
    "                ax.axhline(y=0, linestyle='dotted', color='k')\n",
    "                ax.set_xlim([-1.1, 1.1])\n",
    "                ax.set_ylim([-1.1, 1.1])\n",
    "        make_pretty_axes(ax)\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7d: branch coding as a function of sparsity of SST->Edend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# branch coding as a function of sparsity of SST->Edend\n",
    "import scipy.stats as stats\n",
    "all_dend_nonlinears = list(set(x['hp']['dend_nonlinearity'] for x in all_data_branch_coding))\n",
    "for dend_nonlinear in all_dend_nonlinears:\n",
    "    sparsities = sorted(list(set([x['hp']['sparse_srsst_to_sredend'] for x in all_data_branch_coding])), reverse=True)\n",
    "    sparsity_vs_diffrulesel = dict.fromkeys(sparsities)\n",
    "    for s in sparsities:\n",
    "        sparsity_vs_diffrulesel[s] = {}              \n",
    "        all_diff_rulesel = []\n",
    "        for x in all_data_branch_coding:\n",
    "            if x['hp']['dend_nonlinearity']!=dend_nonlinear:\n",
    "                continue\n",
    "            if x['hp']['sparse_srsst_to_sredend']==s:\n",
    "                all_diff_rulesel.extend(np.abs(np.array(x['rule_sel_dend1_norm']) - np.array(x['rule_sel_dend2_norm'])))\n",
    "        mean_diff_rulesel = np.mean(all_diff_rulesel)\n",
    "        std_diff_rulesel = np.std(all_diff_rulesel)\n",
    "        sem_diff_rulesel = stats.sem(all_diff_rulesel)\n",
    "        sparsity_vs_diffrulesel[s]['mean_diff_rulesel'] = mean_diff_rulesel\n",
    "        sparsity_vs_diffrulesel[s]['std_diff_rulesel'] = std_diff_rulesel\n",
    "        sparsity_vs_diffrulesel[s]['sem_diff_rulesel'] = sem_diff_rulesel\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[6, 5])    \n",
    "    ax.errorbar(x=sparsities, \n",
    "                   y=[sparsity_vs_diffrulesel[s]['mean_diff_rulesel'] for s in sparsities], \n",
    "                   yerr=[sparsity_vs_diffrulesel[s]['sem_diff_rulesel'] for s in sparsities],\n",
    "                   marker='o',\n",
    "                   color='k')\n",
    "    ax.set_xlim([min(sparsities)-0.1, max(sparsities)+0.1])\n",
    "    ax.set_xlabel('Sparsity', fontsize=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.set_title(dend_nonlinear)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
