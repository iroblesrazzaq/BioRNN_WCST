{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np; np.set_printoptions(precision=2); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=2)\n",
    "seed = 1\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib \n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as pl\n",
    "from mpltern.ternary.datasets import get_scatter_points\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import itertools \n",
    "import random; random.seed(0)\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import scipy; from scipy import stats; from scipy.stats import wilcoxon\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import sys\n",
    "\n",
    "from functions import *\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(sys.version)\n",
    "                \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for Figure 5c (structure in the input weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/model/directory/')):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name+'\\n')\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/model/directory/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "        \n",
    "        # load the neural data\n",
    "        with open('/where/test/data/is/stored/'+model_name+'_testdata_noiseless', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_test_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        if mean_test_perf<=0.8:\n",
    "            print('perf too low ({}), pass\\n'.format(mean_test_perf))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "        \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "        error_trials = trial_labels['error_trials']\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                         rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                         rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "                                         resp_trs_stable = resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                         stims=test_data['stims'], error_trials=trial_labels['error_trials'], trial_labels=trial_labels)\n",
    "\n",
    "        # define neuron pools\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          rule_threshold=0, resp_threshold=0)\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        w_in_eff = model.rnn.effective_weight(w=model.rnn.w_in, mask=model.rnn.mask_in).detach().cpu().numpy()\n",
    "\n",
    "        all_data.append({'model': model, 'model_name': model_name, 'hp': hp_test, \n",
    "                         'n_sr_esoma': model.rnn.n['sr_esoma'], 'n_branches': model.rnn.n_branches, \n",
    "                         'w_in_eff': w_in_eff, 'subcg_sr_idx': subcg_sr_idx, 'all_sels': all_sels})\n",
    "                \n",
    "print('Elapsed time: {}s'.format(time.time()-start))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "w_in_large_all_models = []\n",
    "w_in_large_ref_all_models = []\n",
    "w_in_large_test_all_models = []\n",
    "w_in_small_all_models = []\n",
    "\n",
    "for data in all_data:\n",
    "    if data['hp']['dend_nonlinearity']!='divisive_2':\n",
    "        continue\n",
    "    w_in_larges = []\n",
    "    w_in_large_refs = []\n",
    "    w_in_large_tests = []\n",
    "    w_in_smalls = []\n",
    "    for r in [1, 2]:\n",
    "        for choice in [1, 2, 3]:\n",
    "            for card in ['(0, 0)', '(1, 0)', '(0, 1)', '(1, 1)']:\n",
    "                neuron_id_rule = data['subcg_sr_idx']['rule{}_sr_esoma'.format(r)]\n",
    "                neuron_id_choice = data['subcg_sr_idx']['respc{}_sr_esoma'.format(choice)]\n",
    "                neuron_id_refcard = data['subcg_sr_idx']['ref_card{}_sr_esoma'.format(card)]\n",
    "                neuron_id = [n for n in neuron_id_rule if (n in neuron_id_choice and n in neuron_id_refcard)]    # all neurons that prefer a given combination of rule, choice and reference card (and therefore feature)        \n",
    "                if (r==1 and (card=='(0, 0)' or card=='(0, 1)')) or (r==2 and (card=='(0, 0)' or card=='(1, 0)')):\n",
    "                    feature_id = 0    # this neuron prefers when the matching feature is blue or circle\n",
    "                else:\n",
    "                    feature_id = 1    # this neuron prefers when the matching feature is red or square \n",
    "#                 input_neuron_id_large = [2*(r-1) + feature_id, 4+4*(choice-1) + 2*(r-1) + feature_id]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                input_neuron_id_large_ref = 2*(r-1) + feature_id\n",
    "                input_neuron_id_large_test = 4+4*(choice-1) + 2*(r-1) + feature_id\n",
    "                input_neuron_id_large = [input_neuron_id_large_ref, input_neuron_id_large_test]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                input_neuron_id_small = [i for i in range(data['w_in_eff'].shape[0]) if i not in input_neuron_id_large]\n",
    "                for n in neuron_id:\n",
    "                    dend_id = [n + (b+1)*data['n_sr_esoma'] for b in range(data['n_branches'])]    # the dendritic indices\n",
    "                    w_in_large = data['w_in_eff'][np.ix_(input_neuron_id_large, dend_id)]\n",
    "                    w_in_small = data['w_in_eff'][np.ix_(input_neuron_id_small, dend_id)]\n",
    "                    w_in_large_ref = data['w_in_eff'][input_neuron_id_large_ref, dend_id]\n",
    "                    w_in_large_test = data['w_in_eff'][input_neuron_id_large_test, dend_id]\n",
    "                    \n",
    "                    w_in_larges.append(np.mean(w_in_large))\n",
    "                    w_in_smalls.append(np.mean(w_in_small))\n",
    "                    w_in_large_refs.append(np.mean(w_in_large_ref))\n",
    "                    w_in_large_tests.append(np.mean(w_in_large_test))\n",
    "\n",
    "    w_in_large_all_models.extend(w_in_larges)\n",
    "    w_in_large_ref_all_models.extend(w_in_large_refs)\n",
    "    w_in_large_test_all_models.extend(w_in_large_tests)\n",
    "    w_in_small_all_models.extend(w_in_smalls)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(len(w_in_larges)):\n",
    "        ax.plot([w_in_larges[i], w_in_smalls[i]], marker='o', markersize=10, alpha=0.5, color='k')\n",
    "    y = [w_in_larges, w_in_smalls]\n",
    "    t, p = scipy.stats.ttest_ind(y[0], y[1])\n",
    "    print('t={}, p-value={}'.format(t, p))\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_ylabel(r'Input weight', fontsize=20)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nfeature', 'Non-preferred\\nfeature'], rotation=0, fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=[7,7])\n",
    "fig.patch.set_facecolor('white')\n",
    "for i in range(len(w_in_large_all_models)):\n",
    "    ax.plot([w_in_large_all_models[i], w_in_small_all_models[i]], marker='o', markersize=10, alpha=0.02, color='k')\n",
    "y = [w_in_large_all_models, w_in_small_all_models]\n",
    "t, p = scipy.stats.ttest_ind(y[0], y[1])\n",
    "print('t={}, p-value={}'.format(t, p))\n",
    "ax.set_xlim([-0.3, 1.3])\n",
    "ax.set_ylabel(r'Input weight', fontsize=20)\n",
    "ax.set_xticks([0, 1])\n",
    "make_pretty_axes(ax, labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for Figure 5d (structure in the output weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "all_data_wout = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/model/directory/')):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name+'\\n')\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/model/directory/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "        \n",
    "        # load neural data\n",
    "        with open('/where/test/data/is/stored/'+model_name+'_testdata_noiseless', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_test_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        if mean_test_perf<=0.8:\n",
    "            print('perf too low ({}), pass\\n'.format(mean_test_perf))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "        \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "        error_trials = trial_labels['error_trials']\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                         rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                         rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "                                         resp_trs_stable = resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                         stims=test_data['stims'], error_trials=trial_labels['error_trials'], trial_labels=trial_labels)\n",
    "\n",
    "        # define neuron pools\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          rule_threshold=0, resp_threshold=0)\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        w_out_eff = model.rnn.effective_weight(w=model.rnn.w_out, mask=model.mask_out).detach().cpu().numpy()\n",
    "\n",
    "        all_data_wout.append({\n",
    "                              'model': model, \n",
    "                              'model_name': model_name, \n",
    "                              'hp': hp_test, \n",
    "                              'w_out_eff': w_out_eff,\n",
    "                              'subcg_sr_idx': subcg_sr_idx\n",
    "                             })\n",
    "                \n",
    "print('Elapsed time: {}s'.format(time.time()-start))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wout_pref_all = []\n",
    "wout_nonpref_all = []\n",
    "\n",
    "for data in all_data_wout:\n",
    "    if data['hp']['dend_nonlinearity']!='divisive_2':\n",
    "        continue\n",
    "    print(data['model_name'])\n",
    "    wout_pref = []\n",
    "    wout_nonpref = []\n",
    "    wout = data['w_out_eff']\n",
    "    for resp in ['c1', 'c2', 'c3']:\n",
    "        neuron_idx = data['subcg_sr_idx']['resp{}_sr_esoma'.format(resp)]\n",
    "        if resp=='c1':\n",
    "            wout_idx_pref, wout_idx_nonpref = 0, [1, 2]\n",
    "        elif resp=='c2':\n",
    "            wout_idx_pref, wout_idx_nonpref = 1, [0, 2]\n",
    "        elif resp=='c3':\n",
    "            wout_idx_pref, wout_idx_nonpref = 2, [0, 1]\n",
    "        wout_pref.extend(wout[neuron_idx, wout_idx_pref])\n",
    "        wout_nonpref.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "        wout_pref_all.extend(wout[neuron_idx, wout_idx_pref])\n",
    "        wout_nonpref_all.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.plot([0, 1], [wout_pref, wout_nonpref], color='k', marker='o', alpha=0.5)\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "    ax.set_ylabel('Readout weight', fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "print('all models')\n",
    "fig, ax = plt.subplots(figsize=[7,7])\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.plot([0, 1], [wout_pref_all, wout_nonpref_all], color='k', marker='o', alpha=0.02)\n",
    "ax.set_xlim([-0.3, 1.3])\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "ax.set_ylabel('Readout weight', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
