{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np; np.set_printoptions(precision=2, threshold=100); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=2, threshold=100)\n",
    "seed = 1 \n",
    "\n",
    "torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt; plt.rc('font', size=12)\n",
    "import matplotlib   \n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys \n",
    "import itertools\n",
    "import random; random.seed(0)\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "\n",
    "import sys\n",
    "# from task import *\n",
    "from functions import *\n",
    "# from train import *\n",
    "# from model import *\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(sys.version)\n",
    "                \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "plt.rc('font', size=18)\n",
    "perfs_across_models = []\n",
    "for model_name in sorted(os.listdir('/where/models/are/stored/')):    # replace with the model directory on your machine\n",
    "    if ('2023-05-10' in model_name) and 'success' in model_name:    # sub-select models as you wish\n",
    "        print(model_name)\n",
    "        path_to_file = '/where/models/are/stored/' + model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file, model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "        if hp_test['dt']!=10:\n",
    "            print('pass\\n')\n",
    "            continue    # put the filtering condition here\n",
    "        \n",
    "        # make noiseless\n",
    "        model.rnn.network_noise = 0\n",
    "        model.output_noise = 0\n",
    "        hp_test['input_noise_perceptual'] = 0\n",
    "        hp_test['input_noise_rule'] = 0\n",
    "        \n",
    "\n",
    "        with open('/where/data/for/test/run/is/stored/'+model_name+'_testdata_noiseless', 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        perfs = neural_data['test_data']['perfs']\n",
    "        perf_rules = neural_data['test_data']['perf_rules']\n",
    "        mean_perf = np.mean([_[0] for _ in perfs])\n",
    "        rules = neural_data['test_data']['rules']\n",
    "        switch_trials = [tr for tr in range(len(rules)-1) if rules[tr]!=rules[tr+1]]\n",
    "        \n",
    "        mean_perf_rule = np.mean([_[0] for _ in perf_rules])\n",
    "        perfs_across_models.append({'model': model_name, 'mean_perf': mean_perf, 'mean_perf_rule': mean_perf_rule, 'switch_trials': switch_trials, 'switch_to_color_trials': switch_to_color_trials, 'switch_to_shape_trials': switch_to_shape_trials, 'perfs': perfs, 'perf_rules': perf_rules})\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perf_after_switch(switch_trials, perfs, n_trs_max=10, title='Figure'):\n",
    "    \"\"\" \n",
    "        Plot the performance aligned to rule switch\n",
    "        \n",
    "        Args:\n",
    "            n_trs_max: plot the performance for how many number of trials after switch \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 1, figsize=[7, 10])\n",
    "    fig.suptitle(title)\n",
    "    ax[0].set_xlabel('Trial after switch')\n",
    "    ax[1].set_xlabel('Trial after switch')\n",
    "    ax[0].set_ylabel('Perf')\n",
    "    ax[1].set_ylabel('Perf for rule')\n",
    "    for i in range(2):\n",
    "        ax[i].set_xticks(np.arange(n_trs_max))\n",
    "#     ax[0].set_xlim([1, 50])\n",
    "#     ax[1].set_xlim([1, 50])\n",
    "    # the performance n trials after a switch\n",
    "    perf_after_switch = dict.fromkeys(np.arange(0, n_trs_max))\n",
    "    perf_rule_after_switch = dict.fromkeys(np.arange(0, n_trs_max))\n",
    "    for key in perf_after_switch.keys():    \n",
    "        perf_after_switch[key] = []\n",
    "        perf_rule_after_switch[key] = []\n",
    "    for n_switch in range(len(switch_trials)-1):\n",
    "        current_switch = switch_trials[n_switch]\n",
    "        print('current_switch={}'.format(current_switch))\n",
    "#         next_switch = switch_trials[n_switch+1]\n",
    "#         ax[0].plot(perfs[current_switch:next_switch], alpha=0.25, color='gray')\n",
    "#         ax[1].plot(perf_rules[current_switch:next_switch], alpha=0.25, color='gray')\n",
    "        for tr in range(0, n_trs_max):\n",
    "            if tr==0:\n",
    "                perf_after_switch[tr].append(1-perfs[current_switch+tr])\n",
    "                perf_rule_after_switch[tr].append(1-perf_rules[current_switch+tr])\n",
    "            else:\n",
    "                perf_after_switch[tr].append(perfs[current_switch+tr])\n",
    "                perf_rule_after_switch[tr].append(perf_rules[current_switch+tr])\n",
    "    print('perf_after_switch={}'.format(perf_after_switch))\n",
    "    x = np.arange(0, n_trs_max)\n",
    "    y = [np.mean(perf_after_switch[tr]) for tr in perf_after_switch.keys()]\n",
    "    print('y={}'.format(y))\n",
    "#     y_err = [np.std(perf_after_switch[tr]) for tr in perf_after_switch.keys()]\n",
    "    y_err = [scipy.stats.sem(perf_after_switch[tr]) for tr in perf_after_switch.keys()]\n",
    "    y_rule = [np.mean(perf_rule_after_switch[tr]) for tr in perf_after_switch.keys()]\n",
    "#     y_err_rule = [np.std(perf_rule_after_switch[tr]) for tr in perf_after_switch.keys()]\n",
    "    y_err_rule = [scipy.stats.sem(perf_rule_after_switch[tr]) for tr in perf_after_switch.keys()]\n",
    "    ax[0].errorbar(x=x, y=y, yerr=y_err, color='gray', marker='s', fillstyle='none')\n",
    "    ax[1].errorbar(x=x, y=y_rule, yerr=y_err_rule, color='gray', marker='s', fillstyle='none')\n",
    "    for i in range(2):\n",
    "        ax[i].axhline(y=1/3, color='k', linestyle='dotted')\n",
    "        make_pretty_axes(ax[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing Figure 1 c, d, f\n",
    "The name of the model in Figure 1f: success_2023-12-22-16-37-35_wcst_15_early_stopping_correct2\n",
    "\n",
    "Please re-run the first block by replacing '2023-05-10' with '2023-12-22' before running the following block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance as a function of trial number\n",
    "\n",
    "for data in perfs_across_models:\n",
    "    print(data['model'])\n",
    "    \n",
    "    perfs = [_[0] for _ in data['perfs']]\n",
    "    perf_rules = [_[0] for _ in data['perf_rules']]\n",
    "    switch_trials = data['switch_trials']\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=[50, 10])\n",
    "    fig.suptitle('Performance')\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Perf')\n",
    "    ax.set_xlim([0, 1000])\n",
    "    ax.plot(perfs, color='k', linewidth=2)\n",
    "    for tr in switch_trials:\n",
    "        ax.axvline(x=tr+1, color='#e6550d', linewidth=5)\n",
    "    make_pretty_axes(ax)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    plot_perf_after_switch(switch_trials=data['switch_trials'], perfs=perfs, title='All switches')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
