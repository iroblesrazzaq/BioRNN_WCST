{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088c273a-8867-4c74-8724-db941748c004",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# exc -> SST connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a4f0f-94c9-43d4-b3f4-f42e956ac2c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Look at the top-down projection to different neuron pools in SM\n",
    "# from scipy.stats.stats import pearsonr\n",
    "\n",
    "# start = time.time()\n",
    "# plt.rc('font', size=12)\n",
    "\n",
    "# # all_rs = []\n",
    "# # all_ps = []\n",
    "# all_data = []\n",
    "\n",
    "# for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "# #     if 'full_model' in model_name and 'wcst' in model_name and 'success' in model_name:\n",
    "#     if ('2023-05-01' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "#         print(model_name+'\\n')\n",
    "        \n",
    "# #         # load model\n",
    "#         path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "#         with HiddenPrints():\n",
    "#             model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, \n",
    "#                                                                             simple=False, plot=False, toprint=False)\n",
    "#         if hp_test['dt']!=10 or hp_test['dend_nonlinearity'] not in ['subtractive', 'divisive_2']:\n",
    "#             continue\n",
    "#         if len(hp_test['cell_group_list'])==2:\n",
    "#             print('pass\\n')\n",
    "#             continue\n",
    "# #         if hp_test['dend_nonlinearity'] not in ['v2', 'subtract_v2', 'old_v2', 'subtract_v3']:\n",
    "# #             continue\n",
    "# #         if hp_test['sparse_srsst_to_sredend']!=0:\n",
    "# #             continue\n",
    "        \n",
    "#         for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation', 'no_pfcesoma_to_srsst']:\n",
    "#             print(key, hp_test[key])\n",
    "\n",
    "#         # make noiseless\n",
    "# #         model.rnn.network_noise = 0\n",
    "# #         hp_test['input_noise_perceptual'] = 0\n",
    "# #         hp_test['input_noise_rule'] = 0\n",
    "        \n",
    "#         # generate some neural data\n",
    "# #         neural_data = generate_neural_data_test(model=model, n_trials_test=100, switch_every_test=10, to_plot=False, \n",
    "# #                                         hp_test=hp_test, hp_task_test=hp_task_test, compute_current=False)\n",
    "#         with open('/scratch/yl4317/two_module_rnn/saved_testdata/{}'.format(model_name+'_testdata_noiseless_no_current_matrix'), 'rb') as f:\n",
    "#             neural_data = pickle.load(f)\n",
    "#         test_data = neural_data['test_data']\n",
    "#         mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "#         mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "#         if mean_perf<0.8 or mean_perf_rule<0.8:\n",
    "#             print('low performing model ({}/{})'.format(mean_perf, mean_perf_rule))\n",
    "#             continue\n",
    "#         rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "# #         current_matrix = neural_data['current_matrix']\n",
    "        \n",
    "#         # generate trial labels\n",
    "#         trial_labels = label_trials_wcst(test_data=test_data)\n",
    "#         rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "#         rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "#         rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "#         rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "#         c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "#         c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "#         c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "#         resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "#         error_trials = trial_labels['error_trials']\n",
    "        \n",
    "#         # compute cell selectivity\n",
    "#         all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "#                                      rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "#                                      rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "#                                      resp_trs_stable = resp_trs_stable, \n",
    "#                                      stims=test_data['stims'], error_trials=trial_labels['error_trials'], trs_by_center_card=trial_labels['trs_by_center_card_stable'])\n",
    "#         resp_sel_normalized = all_sels['resp_normalized']\n",
    "#         rule_sel_normalized = all_sels['rule_normalized_activity']\n",
    "\n",
    "#         # subregions\n",
    "#         subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "#                                           rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], \n",
    "#                                           rule1_trs_stable=rule1_trs_stable, \n",
    "#                                           rule2_trs_stable=rule2_trs_stable, \n",
    "#                                           rule_threshold=0, resp_threshold=0,\n",
    "#                                           ref_card_sel=all_sels['ref_card_normalized'])\n",
    "#         for subcg in subcg_sr_idx.keys():\n",
    "#             model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        \n",
    "#         # analysis 2, compare connection strength from different populations\n",
    "#         rule1_exc_idx, rule2_exc_idx, rule1_sst_idx, rule2_sst_idx = subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule1_sr_sst'], subcg_sr_idx['rule2_sr_sst']\n",
    "        \n",
    "#         w_rec_eff = model.rnn.effective_weight(w=model.rnn.w_rec, mask=model.rnn.mask)\n",
    "#         w_rec_eff = w_rec_eff.detach().numpy()\n",
    "        \n",
    "#         w_exc_rule1_sst_rule1 = np.mean(w_rec_eff[np.ix_(rule1_exc_idx, rule1_sst_idx)], axis=0)\n",
    "#         w_exc_rule1_sst_rule2 = np.mean(w_rec_eff[np.ix_(rule1_exc_idx, rule2_sst_idx)], axis=0)\n",
    "#         w_exc_rule2_sst_rule1 = np.mean(w_rec_eff[np.ix_(rule2_exc_idx, rule1_sst_idx)], axis=0)\n",
    "#         w_exc_rule2_sst_rule2 = np.mean(w_rec_eff[np.ix_(rule2_exc_idx, rule2_sst_idx)], axis=0)\n",
    "        \n",
    "#         w_same_rule = np.concatenate((w_exc_rule1_sst_rule1, w_exc_rule2_sst_rule2))    # weight to VIP neurons from PFC exc neurons selective for the same rule\n",
    "#         w_diff_rule = np.concatenate((w_exc_rule1_sst_rule2, w_exc_rule2_sst_rule1))\n",
    "        \n",
    "        \n",
    "        \n",
    "#         all_data.append({'name': model_name, \n",
    "#                          'hp': hp_test,\n",
    "#                          'w_same_rule': w_same_rule,\n",
    "#                          'w_diff_rule': w_diff_rule,\n",
    "#                         })\n",
    "\n",
    "# print(time.time()-start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01866e4d-50a4-40bd-bd8e-3f04133c9ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # compare the weight from PFC neurons that have the same/different rule preference\n",
    "\n",
    "# # plot each model\n",
    "# for x in all_data:\n",
    "#     print(x['name'])\n",
    "    \n",
    "#     for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation']:\n",
    "#         print(key, x['hp'][key])\n",
    "\n",
    "#     y = [x['w_same_rule'], x['w_diff_rule']]\n",
    "#     if np.array(y).size==0:\n",
    "#         print('size of y is 0, pass')\n",
    "#         continue\n",
    "\n",
    "#     # plot\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=[5, 6])\n",
    "#     fig.patch.set_facecolor('white')\n",
    "\n",
    "#     # do statistical test\n",
    "#     ttest = stats.ttest_ind(y[0], y[1])\n",
    "#     ax.set_title('{:.2f}, p={:.4f}'.format(ttest[0], ttest[1]))\n",
    "#     ax.plot([0, 1], y, marker='o', color='k', alpha=0.5)\n",
    "#     ax.bar([0, 1],\n",
    "#                 height=[np.mean(yi) for yi in y],\n",
    "#     #            yerr=[stats.sem(yi) for yi in yy],    # error bars\n",
    "#                capsize=12, # error bar cap width in points\n",
    "#                width=0.2,    # bar width\n",
    "#                color=(0,0,0,0),\n",
    "#                edgecolor=[(0, 0, 1, 1), (1, 0, 0, 1)]\n",
    "#              )\n",
    "\n",
    "#     make_pretty_axes(ax)\n",
    "#     ax.set_xticks([0, 1])\n",
    "#     ax.set_xticklabels(['E->SST, same rule', 'E->SST, different rule'], rotation=15)\n",
    "#     ax.set_xlim([-0.2, 1.2])\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # aggregate across models\n",
    "# w_same_rule_all = []\n",
    "# w_diff_rule_all = []  \n",
    "# for x in all_data:\n",
    "#     w_same_rule_all.extend(x['w_same_rule'])\n",
    "#     w_diff_rule_all.extend(x['w_diff_rule'])\n",
    "# yy = [w_same_rule_all, w_diff_rule_all]\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=[5, 6])\n",
    "# fig.patch.set_facecolor('white')\n",
    "\n",
    "# # do statistical test\n",
    "# ttest = stats.ttest_ind(yy[0], yy[1])\n",
    "# ax.set_title('{:.2f}, p={:.4f}'.format(ttest[0], ttest[1]))\n",
    "\n",
    "# ax.plot([0, 1], yy, marker='o', color='k', alpha=0.1)\n",
    "# ax.bar([0, 1],\n",
    "#                 height=[np.mean(yi) for yi in yy],\n",
    "#     #            yerr=[stats.sem(yi) for yi in yy],    # error bars\n",
    "#                capsize=12, # error bar cap width in points\n",
    "#                width=0.2,    # bar width\n",
    "#                color=(0,0,0,0),\n",
    "#                edgecolor=[(0, 0, 1, 1), (1, 0, 0, 1)]\n",
    "#               )\n",
    "# ax.set_xticks([0, 1])\n",
    "# ax.set_xticklabels(['E->SST, same rule', 'E->SST, different rule'], rotation=15)\n",
    "# ax.set_yticklabels(np.round(ax.get_yticks(), 2))\n",
    "# ax.set_xlim([-0.2, 1.2])\n",
    "# make_pretty_axes(ax)\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f8c2c-27da-49f3-bced-16f607b31db8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SST -> PV connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b0dad-774e-42ea-b8d1-20e8aac4ff54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the top-down projection to different neuron pools in SM\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "start = time.time()\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "# all_rs = []\n",
    "# all_ps = []\n",
    "all_data = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "#     if 'full_model' in model_name and 'wcst' in model_name and 'success' in model_name:\n",
    "    if ('2023-05-01' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name+'\\n')\n",
    "        \n",
    "#         # load model\n",
    "        path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, \n",
    "                                                                            simple=False, plot=False, toprint=False)\n",
    "        if hp_test['dt']!=10 or hp_test['dend_nonlinearity'] not in ['subtractive', 'divisive_2']:\n",
    "            continue\n",
    "        if len(hp_test['cell_group_list'])==2:\n",
    "            print('pass\\n')\n",
    "            continue\n",
    "#         if hp_test['dend_nonlinearity'] not in ['v2', 'subtract_v2', 'old_v2', 'subtract_v3']:\n",
    "#             continue\n",
    "#         if hp_test['sparse_srsst_to_sredend']!=0:\n",
    "#             continue\n",
    "        \n",
    "        for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation', 'no_pfcesoma_to_srsst']:\n",
    "            print(key, hp_test[key])\n",
    "\n",
    "        # make noiseless\n",
    "#         model.rnn.network_noise = 0\n",
    "#         hp_test['input_noise_perceptual'] = 0\n",
    "#         hp_test['input_noise_rule'] = 0\n",
    "        \n",
    "        # generate some neural data\n",
    "#         neural_data = generate_neural_data_test(model=model, n_trials_test=100, switch_every_test=10, to_plot=False, \n",
    "#                                         hp_test=hp_test, hp_task_test=hp_task_test, compute_current=False)\n",
    "        with open('/scratch/yl4317/two_module_rnn/saved_testdata/{}'.format(model_name+'_testdata_noiseless_no_current_matrix'), 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        if mean_perf<0.8 or mean_perf_rule<0.8:\n",
    "            print('low performing model ({}/{})'.format(mean_perf, mean_perf_rule))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "#         current_matrix = neural_data['current_matrix']\n",
    "        \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "        error_trials = trial_labels['error_trials']\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                     rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                     rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "                                     resp_trs_stable = resp_trs_stable, \n",
    "                                     stims=test_data['stims'], error_trials=trial_labels['error_trials'], trs_by_center_card=trial_labels['trs_by_center_card_stable'])\n",
    "        resp_sel_normalized = all_sels['resp_normalized']\n",
    "        rule_sel_normalized = all_sels['rule_normalized_activity']\n",
    "\n",
    "        # subregions\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], \n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          rule_threshold=0, resp_threshold=0,\n",
    "                                          ref_card_sel=all_sels['ref_card_normalized'])\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        \n",
    "        # analysis 2, compare connection strength from different populations\n",
    "        rule1_pv_idx, rule2_pv_idx, rule1_sst_idx, rule2_sst_idx = subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule1_sr_sst'], subcg_sr_idx['rule2_sr_sst']\n",
    "        if len(rule1_pv_idx)==0 or len(rule2_pv_idx)==0 or len(rule1_sst_idx)==0 or len(rule2_sst_idx)==0:\n",
    "            print('# of rule 1/2 PV/SST neuron = {}/{} (PV), {}/{}(SST), pass'.format(len(rule1_pv_idx), len(rule2_pv_idx), len(rule1_sst_idx), len(rule2_sst_idx)))\n",
    "            continue\n",
    "        w_rec_eff = model.rnn.effective_weight(w=model.rnn.w_rec, mask=model.rnn.mask)\n",
    "        w_rec_eff = w_rec_eff.detach().numpy()\n",
    "        \n",
    "        w_sst_rule1_pv_rule1 = np.mean(w_rec_eff[np.ix_(rule1_sst_idx, rule1_pv_idx)], axis=0)\n",
    "        w_sst_rule1_pv_rule2 = np.mean(w_rec_eff[np.ix_(rule1_sst_idx, rule2_pv_idx)], axis=0)\n",
    "        w_sst_rule2_pv_rule1 = np.mean(w_rec_eff[np.ix_(rule2_sst_idx, rule1_pv_idx)], axis=0)\n",
    "        w_sst_rule2_pv_rule2 = np.mean(w_rec_eff[np.ix_(rule2_sst_idx, rule2_pv_idx)], axis=0)\n",
    "        \n",
    "        w_same_rule = np.concatenate((w_sst_rule1_pv_rule1, w_sst_rule2_pv_rule2))    # weight to VIP neurons from PFC exc neurons selective for the same rule\n",
    "        w_diff_rule = np.concatenate((w_sst_rule1_pv_rule2, w_sst_rule2_pv_rule1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_data.append({'name': model_name, \n",
    "                         'hp': hp_test,\n",
    "                         'w_same_rule': w_same_rule,\n",
    "                         'w_diff_rule': w_diff_rule,\n",
    "                        })\n",
    "\n",
    "print(time.time()-start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00088d-7f15-4163-aa4a-28189b6133f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare the weight from PFC neurons that have the same/different rule preference\n",
    "\n",
    "# plot each model\n",
    "for x in all_data:\n",
    "    print(x['name'])\n",
    "    \n",
    "    for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation']:\n",
    "        print(key, x['hp'][key])\n",
    "\n",
    "    y = [x['w_same_rule'], x['w_diff_rule']]\n",
    "    if np.array(y).size==0:\n",
    "        print('size of y is 0, pass')\n",
    "        continue\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[5, 6])\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    # do statistical test\n",
    "    ttest = stats.ttest_ind(y[0], y[1])\n",
    "    ax.set_title('{:.2f}, p={:.4f}'.format(ttest[0], ttest[1]))\n",
    "    ax.plot([0, 1], y, marker='o', color='k', alpha=0.5)\n",
    "    ax.bar([0, 1],\n",
    "                height=[np.mean(yi) for yi in y],\n",
    "    #            yerr=[stats.sem(yi) for yi in yy],    # error bars\n",
    "               capsize=12, # error bar cap width in points\n",
    "               width=0.2,    # bar width\n",
    "               color=(0,0,0,0),\n",
    "               edgecolor=[(0, 0, 1, 1), (1, 0, 0, 1)]\n",
    "             )\n",
    "\n",
    "    make_pretty_axes(ax)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['SST->PV, same rule', 'SST->PV, different rule'], rotation=15)\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# aggregate across models\n",
    "w_same_rule_all = []\n",
    "w_diff_rule_all = []  \n",
    "for x in all_data:\n",
    "    w_same_rule_all.extend(x['w_same_rule'])\n",
    "    w_diff_rule_all.extend(x['w_diff_rule'])\n",
    "yy = [w_same_rule_all, w_diff_rule_all]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=[5, 6])\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# do statistical test\n",
    "ttest = stats.ttest_ind(yy[0], yy[1])\n",
    "ax.set_title('{:.2f}, p={:.4f}'.format(ttest[0], ttest[1]))\n",
    "\n",
    "ax.plot([0, 1], yy, marker='o', color='k', alpha=0.1)\n",
    "ax.bar([0, 1],\n",
    "                height=[np.mean(yi) for yi in yy],\n",
    "    #            yerr=[stats.sem(yi) for yi in yy],    # error bars\n",
    "               capsize=12, # error bar cap width in points\n",
    "               width=0.2,    # bar width\n",
    "               color=(0,0,0,0),\n",
    "               edgecolor=[(0, 0, 1, 1), (1, 0, 0, 1)]\n",
    "              )\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['SST->PV, same rule', 'SST->PV, different rule'], rotation=15)\n",
    "ax.set_yticklabels(np.round(ax.get_yticks(), 2))\n",
    "ax.set_xlim([-0.2, 1.2])\n",
    "make_pretty_axes(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8b5e6-736b-4704-841e-20bb59bac497",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Look at the weight between SST and VIP neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cf8b9-8329-4b49-b1db-28839f0c05e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the top-down projection to different neuron pools in SM\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "start = time.time()\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "plot = True\n",
    "\n",
    "# all_rs = []\n",
    "# all_ps = []\n",
    "all_data_sstvipconn = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/scratch/yl4317/two_module_rnn/saved_models/')):\n",
    "#     if 'full_model' in model_name and 'wcst' in model_name and 'success' in model_name:\n",
    "    if ('2023-05-03' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name+'\\n')\n",
    "        \n",
    "#         # load model\n",
    "        path_to_file = '/scratch/yl4317/two_module_rnn/saved_models/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file,model_name=model_name, \n",
    "                                                                            simple=False, plot=False, toprint=False)\n",
    "        if hp_test['dt']!=10 or hp_test['dend_nonlinearity'] not in ['subtractive', 'divisive_2']:\n",
    "            continue\n",
    "        if len(hp_test['cell_group_list'])==2:\n",
    "            print('pass\\n')\n",
    "            continue\n",
    "#         if hp_test['dend_nonlinearity'] not in ['v2', 'subtract_v2', 'old_v2', 'subtract_v3']:\n",
    "#             continue\n",
    "#         if hp_test['sparse_srsst_to_sredend']!=0:\n",
    "#             continue\n",
    "        \n",
    "        for key in ['dend_nonlinearity', 'sparse_srsst_to_sredend', 'initialization_weights', 'activation']:\n",
    "            print(key, hp_test[key])\n",
    "\n",
    "        # make noiseless\n",
    "#         model.rnn.network_noise = 0\n",
    "#         hp_test['input_noise_perceptual'] = 0\n",
    "#         hp_test['input_noise_rule'] = 0\n",
    "        \n",
    "        # generate some neural data\n",
    "#         neural_data = generate_neural_data_test(model=model, n_trials_test=100, switch_every_test=10, to_plot=False, \n",
    "#                                         hp_test=hp_test, hp_task_test=hp_task_test, compute_current=False)\n",
    "        with open('/scratch/yl4317/two_module_rnn/saved_testdata/{}'.format(model_name+'_testdata_noiseless_no_current_matrix'), 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        if mean_perf<0.8 or mean_perf_rule<0.8:\n",
    "            print('low performing model ({}/{})'.format(mean_perf, mean_perf_rule))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "#         current_matrix = neural_data['current_matrix']\n",
    "        \n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        rule1_trs_stable = trial_labels['rule1_trs_stable']\n",
    "        rule2_trs_stable = trial_labels['rule2_trs_stable']\n",
    "        rule1_trs_after_error = trial_labels['rule1_trs_after_error']\n",
    "        rule2_trs_after_error = trial_labels['rule2_trs_after_error']\n",
    "        c1_trs_stable = trial_labels['c1_trs_stable']\n",
    "        c2_trs_stable = trial_labels['c2_trs_stable']\n",
    "        c3_trs_stable = trial_labels['c3_trs_stable']\n",
    "        resp_trs_stable = {'c1': c1_trs_stable, 'c2': c2_trs_stable, 'c3': c3_trs_stable}    # to be used as an argument in the \"compute_sel_wcst\" function\n",
    "        error_trials = trial_labels['error_trials']\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                     rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                     rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error=trial_labels['rule2_trs_after_error'],\n",
    "                                     resp_trs_stable = resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                     stims=test_data['stims'], error_trials=trial_labels['error_trials'])\n",
    "        resp_sel_normalized = all_sels['resp_normalized']\n",
    "        rule_sel_normalized = all_sels['rule_normalized_activity']\n",
    "\n",
    "        # subregions\n",
    "        subcg_pfc_idx = define_subpop_pfc(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], err_sel=all_sels['error_normalized'], \n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          rule1_after_error_trs=rule1_trs_after_error,\n",
    "                                          rule2_after_error_trs=rule2_trs_after_error,\n",
    "                                          rule_threshold=0.5, err_threshold=0.5)\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], \n",
    "                                          rule1_trs_stable=rule1_trs_stable, \n",
    "                                          rule2_trs_stable=rule2_trs_stable, \n",
    "                                          ref_card_sel = all_sels['ref_card_normalized'],\n",
    "                                          rule_threshold=0, resp_threshold=0)\n",
    "        for subcg in subcg_pfc_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_pfc_'+subcg] = subcg_pfc_idx[subcg]\n",
    "        for subcg in subcg_sr_idx.keys():\n",
    "            model.rnn.cg_idx['subcg_sr_'+subcg] = subcg_sr_idx[subcg]\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        #=== analysis ===#\n",
    "        w_rec_eff = model.rnn.effective_weight(w=model.rnn.w_rec, mask=model.rnn.mask)\n",
    "        w_rec_eff = w_rec_eff.detach().numpy()\n",
    "        rule1_vip_to_rule1_sst = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_vip'], subcg_sr_idx['rule1_sr_sst'])])\n",
    "        rule1_vip_to_rule2_sst = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_vip'], subcg_sr_idx['rule2_sr_sst'])])\n",
    "        rule2_vip_to_rule1_sst = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_vip'], subcg_sr_idx['rule1_sr_sst'])])\n",
    "        rule2_vip_to_rule2_sst = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_vip'], subcg_sr_idx['rule2_sr_sst'])])\n",
    "        rule1_sst_to_rule1_vip = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_sst'], subcg_sr_idx['rule1_sr_vip'])])\n",
    "        rule1_sst_to_rule2_vip = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_sst'], subcg_sr_idx['rule2_sr_vip'])])\n",
    "        rule2_sst_to_rule1_vip = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_sst'], subcg_sr_idx['rule1_sr_vip'])])\n",
    "        rule2_sst_to_rule2_vip = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_sst'], subcg_sr_idx['rule2_sr_vip'])])\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_data_sstvipconn.append({'name': model_name, \n",
    "                                     'hp': hp_test,\n",
    "                                     'rule1_vip_to_rule1_sst': rule1_vip_to_rule2_sst, \n",
    "                                     'rule1_vip_to_rule2_sst': rule1_vip_to_rule2_sst,\n",
    "                                     'rule2_vip_to_rule1_sst': rule2_vip_to_rule1_sst, \n",
    "                                     'rule2_vip_to_rule2_sst': rule2_vip_to_rule2_sst,\n",
    "                                     'rule1_sst_to_rule1_vip': rule1_sst_to_rule1_vip,\n",
    "                                     'rule1_sst_to_rule2_vip': rule1_sst_to_rule2_vip,\n",
    "                                     'rule2_sst_to_rule1_vip': rule2_sst_to_rule1_vip,\n",
    "                                     'rule2_sst_to_rule2_vip': rule2_sst_to_rule2_vip\n",
    "                                    })\n",
    "        if plot==True:\n",
    "            fig, ax = plot_conn_subpop(weight=w_rec_eff, \n",
    "                                       cg_idx=subcg_sr_idx, \n",
    "                                       subcg_to_plot_sender=['rule1_sr_sst', 'rule2_sr_sst', 'rule1_sr_vip', 'rule2_sr_vip'], \n",
    "                                       subcg_to_plot_receiver=['rule1_sr_sst', 'rule2_sr_sst', 'rule1_sr_vip', 'rule2_sr_vip'])\n",
    "\n",
    "print(time.time()-start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4596d7-ec4b-4746-9a31-7bd187eadea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot connectivity bias\n",
    "fig, ax = plt.subplots(figsize=[4, 6])\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_title('Connectivity biases between sensorimotor SST and VIP cells,\\n across all models\\n', fontsize=20)\n",
    "\n",
    "for data in all_data_sstvipconn:\n",
    "#     if data['hp']['no_pfcesoma_to_srsst']==False or data['hp']['no_pfcesoma_to_srpv']==False:\n",
    "#         continue\n",
    "    conn_bias_vip_to_sst = np.abs(np.mean(data['rule1_vip_to_rule2_sst'])) + np.abs(np.mean(data['rule2_vip_to_rule1_sst'])) - np.abs(np.mean(data['rule1_vip_to_rule1_sst'])) - np.abs(np.mean(data['rule2_vip_to_rule2_sst']))\n",
    "    conn_bias_sst_to_vip = np.abs(np.mean(data['rule1_sst_to_rule2_vip'])) + np.abs(np.mean(data['rule2_sst_to_rule1_vip'])) - np.abs(np.mean(data['rule1_sst_to_rule1_vip'])) - np.abs(np.mean(data['rule2_sst_to_rule2_vip']))\n",
    "#     print([conn_bias_sst_to_vip, conn_bias_vip_to_sst])\n",
    "    ax.plot([conn_bias_sst_to_vip, conn_bias_vip_to_sst], marker='o', color='k', linewidth=1, markersize=10, alpha=1)\n",
    "    ax.set_xticks(np.arange(2))\n",
    "    ax.set_xticklabels([r'SST $\\rightarrow$ VIP', r'VIP $\\rightarrow$ SST'], rotation=30, fontsize=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.axhline(y=0, ls='--', color='k', linewidth=5)\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "#     ax.set_ylim(-1,1)\n",
    "    ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "fig.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0dcfa5-9970-4282-9011-fb983f575e76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Rule selectivity amongst SST and VIP cells in the sensorimotor module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
