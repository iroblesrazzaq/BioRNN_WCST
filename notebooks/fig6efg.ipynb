{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np; np.set_printoptions(precision=2); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=2)\n",
    "seed = 1\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as pl\n",
    "from mpltern.ternary.datasets import get_scatter_points\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import itertools \n",
    "import random; random.seed(0)\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import scipy; from scipy import stats; from scipy.stats import wilcoxon\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from functions import *\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(sys.version)\n",
    "                \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6e, f, g: the connectivity bias between the sensorimotor populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# whether SR E soma are selective for both rule and response\n",
    "start = time.time()\n",
    "plot = True\n",
    "\n",
    "conn_bias_sr_all_models = []\n",
    "\n",
    "for model_name in sorted(os.listdir('/model/directory/')):\n",
    "    if ('2023-05-10' in model_name) and 'wcst' in model_name and 'success' in model_name:\n",
    "        print(model_name)\n",
    "        \n",
    "        # load model\n",
    "        path_to_file = '/model/directory/'+model_name\n",
    "        with HiddenPrints():\n",
    "            model, hp_test, hp_task_test, optim, saved_data = load_model_v2(path_to_file=path_to_file, model_name=model_name, simple=False, plot=False, toprint=False)\n",
    "\n",
    "        # load test data\n",
    "        with open('/where/test/data/is/stored/{}'.format(model_name+'_testdata_noiseless'), 'rb') as f:\n",
    "            neural_data = pickle.load(f)\n",
    "        test_data = neural_data['test_data']\n",
    "        mean_perf = np.mean([_[0] for _ in test_data['perfs']])\n",
    "        mean_perf_rule = np.mean([_[0] for _ in test_data['perf_rules']])\n",
    "        if mean_perf<0.8 or mean_perf_rule<0.8:\n",
    "            print('low performing model ({}/{})'.format(mean_perf, mean_perf_rule))\n",
    "            continue\n",
    "        rnn_activity = neural_data['rnn_activity'].detach().cpu().numpy()\n",
    "\n",
    "        # generate trial labels\n",
    "        trial_labels = label_trials_wcst(test_data=test_data)\n",
    "        resp_trs_stable = {'c1': trial_labels['c1_trs_stable'], 'c2': trial_labels['c2_trs_stable'], 'c3': trial_labels['c3_trs_stable']}\n",
    "        \n",
    "        # compute cell selectivity\n",
    "        all_sels = compute_sel_wcst(rnn_activity=rnn_activity, hp=hp_test, hp_task=hp_task_test, rules=test_data['rules'],\n",
    "                                     rule1_trs_stable=trial_labels['rule1_trs_stable'], rule2_trs_stable=trial_labels['rule2_trs_stable'],\n",
    "                                     rule1_trs_after_error = trial_labels['rule1_trs_after_error'], rule2_trs_after_error = trial_labels['rule2_trs_after_error'],\n",
    "                                     resp_trs_stable=resp_trs_stable, trs_by_center_card=trial_labels['trs_by_center_card_stable'],\n",
    "                                     stims=test_data['stims'], error_trials=trial_labels['error_trials'])\n",
    "        rule_sel_used= all_sels['rule_normalized_activity']    \n",
    "        \n",
    "        \n",
    "        resp_sel_normalized = all_sels['resp_normalized']\n",
    "        rule_sel_normalized = all_sels['rule_normalized_activity']\n",
    "\n",
    "        # subregions\n",
    "        subcg_sr_idx = define_subpop_sr_wcst(model=model, hp_task=hp_task_test, hp=hp_test, rnn_activity=rnn_activity, \n",
    "                                          rule_sel=all_sels['rule_normalized_activity'], resp_sel=all_sels['resp_normalized'], \n",
    "                                          ref_card_sel=all_sels['ref_card_normalized'],\n",
    "                                          rule1_trs_stable=trial_labels['rule1_trs_stable'], \n",
    "                                          rule2_trs_stable=trial_labels['rule2_trs_stable'], \n",
    "                                          rule_threshold=0.0, resp_threshold=0.0)\n",
    "    \n",
    "        # plot connectivity between subpopulations\n",
    "        w_rec_eff = model.rnn.effective_weight(w=model.rnn.w_rec, mask=model.rnn.mask, w_fix=model.rnn.w_fix).detach().cpu().numpy()\n",
    "        if plot==True:\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=['rule1_sr_esoma', 'rule2_sr_esoma', 'rule1_sr_pv', 'rule2_sr_pv'], subcg_to_plot_receiver=['rule1_sr_esoma', 'rule2_sr_esoma', 'rule1_sr_pv', 'rule2_sr_pv'])\n",
    "            resp_pops = ['respc1_sr_esoma', 'respc2_sr_esoma', 'respc3_sr_esoma', 'respc1_sr_pv', 'respc2_sr_pv', 'respc3_sr_pv']\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=resp_pops, subcg_to_plot_receiver=resp_pops)\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=['respc1_sr_pv', 'respc2_sr_pv', 'respc3_sr_pv'], subcg_to_plot_receiver=['respc1_sr_pv', 'respc2_sr_pv', 'respc3_sr_pv'])\n",
    "            shared_feature_pops_color = ['blue_sr_esoma', 'red_sr_esoma', 'blue_sr_pv', 'red_sr_pv']\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=shared_feature_pops_color, subcg_to_plot_receiver=shared_feature_pops_color)\n",
    "            shared_feature_pops_shape = ['circle_sr_esoma', 'triangle_sr_esoma', 'circle_sr_pv', 'triangle_sr_pv']\n",
    "            _, _ = plot_conn_subpop(weight=w_rec_eff, cg_idx=subcg_sr_idx, subcg_to_plot_sender=shared_feature_pops_shape, subcg_to_plot_receiver=shared_feature_pops_shape)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # compute connectivity bias for rule\n",
    "        conn_bias_rulee_rulee = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule1_sr_esoma'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule2_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule2_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule1_sr_esoma'])])\n",
    "        conn_bias_rulee_rulepv = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule1_sr_pv'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule2_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_esoma'], subcg_sr_idx['rule2_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_esoma'], subcg_sr_idx['rule1_sr_pv'])])\n",
    "        conn_bias_rulepv_rulee = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule2_sr_esoma'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule1_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule1_sr_esoma'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule2_sr_esoma'])])\n",
    "        conn_bias_rulepv_rulee = -conn_bias_rulepv_rulee\n",
    "        conn_bias_rulepv_rulepv = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule2_sr_pv'])])\\\n",
    "                                  +np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule1_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule1_sr_pv'], subcg_sr_idx['rule1_sr_pv'])])\\\n",
    "                                  -np.mean(w_rec_eff[np.ix_(subcg_sr_idx['rule2_sr_pv'], subcg_sr_idx['rule2_sr_pv'])])\n",
    "        conn_bias_rulepv_rulepv = -conn_bias_rulepv_rulepv\n",
    "        \n",
    "                     \n",
    "            \n",
    "            \n",
    "        # connectivity bias based on neurons preferring different responses              \n",
    "        conn = {}\n",
    "        conn[('resp_sr_esoma', 'resp_sr_esoma')] = {}\n",
    "        conn[('resp_sr_esoma', 'resp_sr_pv')] = {}\n",
    "        conn[('resp_sr_pv', 'resp_sr_esoma')] = {}\n",
    "        conn[('resp_sr_pv', 'resp_sr_pv')] = {}\n",
    "        for key in conn.keys():\n",
    "            for x in ['same', 'cross']:\n",
    "                conn[key][x] = []\n",
    "        \n",
    "        for resp1 in ['c1', 'c2', 'c3']:\n",
    "            for resp2 in ['c1', 'c2', 'c3']:\n",
    "                if resp1==resp2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('resp_{}'.format(sender), 'resp_{}'.format(receiver))]['same'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['resp{}_{}'.format(resp1, sender)], subcg_sr_idx['resp{}_{}'.format(resp2, receiver)])]))\n",
    "                elif resp1!=resp2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('resp_{}'.format(sender), 'resp_{}'.format(receiver))]['cross'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['resp{}_{}'.format(resp1, sender)], subcg_sr_idx['resp{}_{}'.format(resp2, receiver)])]))     \n",
    "                        \n",
    "        conn_bias_respe_respe = np.mean(conn[('resp_sr_esoma', 'resp_sr_esoma')]['same']) - np.mean(conn[('resp_sr_esoma', 'resp_sr_esoma')]['cross'])\n",
    "        conn_bias_respe_resppv = np.mean(conn[('resp_sr_esoma', 'resp_sr_pv')]['same']) - np.mean(conn[('resp_sr_esoma', 'resp_sr_pv')]['cross'])\n",
    "        conn_bias_resppv_respe = - (np.mean(conn[('resp_sr_pv', 'resp_sr_esoma')]['cross']) - np.mean(conn[('resp_sr_pv', 'resp_sr_esoma')]['same']))\n",
    "        conn_bias_resppv_resppv = - (np.mean(conn[('resp_sr_pv', 'resp_sr_pv')]['cross']) - np.mean(conn[('resp_sr_pv', 'resp_sr_pv')]['same']))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # connectivity bias based on neurons preferring different reference cards\n",
    "        conn = {}\n",
    "        conn[('ref_card_sr_esoma', 'ref_card_sr_esoma')] = {}\n",
    "        conn[('ref_card_sr_esoma', 'ref_card_sr_pv')] = {}\n",
    "        conn[('ref_card_sr_pv', 'ref_card_sr_esoma')] = {}\n",
    "        conn[('ref_card_sr_pv', 'ref_card_sr_pv')] = {}\n",
    "        for key in conn.keys():\n",
    "            for x in ['same', 'cross']:\n",
    "                conn[key][x] = []\n",
    "            \n",
    "        for ref_card1 in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "            for ref_card2 in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "                if ref_card1==ref_card2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('ref_card_{}'.format(sender), 'ref_card_{}'.format(receiver))]['same'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['ref_card{}_{}'.format(ref_card1, sender)], subcg_sr_idx['ref_card{}_{}'.format(ref_card2, receiver)])]))\n",
    "                elif ref_card1!=ref_card2:\n",
    "                    for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                        conn[('ref_card_{}'.format(sender), 'ref_card_{}'.format(receiver))]['cross'].append(np.mean(w_rec_eff[np.ix_(subcg_sr_idx['ref_card{}_{}'.format(ref_card1, sender)], subcg_sr_idx['ref_card{}_{}'.format(ref_card2, receiver)])]))     \n",
    "                        \n",
    "        conn_bias_ref_card_e_ref_card_e = np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_esoma')]['same']) - np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_esoma')]['cross'])\n",
    "        conn_bias_ref_card_e_ref_card_pv = np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_pv')]['same']) - np.mean(conn[('ref_card_sr_esoma', 'ref_card_sr_pv')]['cross'])\n",
    "        conn_bias_ref_card_pv_ref_card_e = - (np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_esoma')]['cross']) - np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_esoma')]['same']))\n",
    "        conn_bias_ref_card_pv_ref_card_pv = - (np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_pv')]['cross']) - np.mean(conn[('ref_card_sr_pv', 'ref_card_sr_pv')]['same']))\n",
    "        \n",
    "        \n",
    "        # connectivity bias based on neurons preferring different reference cards\n",
    "        conn = {}\n",
    "        conn[('shared_feature_sr_esoma', 'shared_feature_sr_esoma')] = {}\n",
    "        conn[('shared_feature_sr_esoma', 'shared_feature_sr_pv')] = {}\n",
    "        conn[('shared_feature_sr_pv', 'shared_feature_sr_esoma')] = {}\n",
    "        conn[('shared_feature_sr_pv', 'shared_feature_sr_pv')] = {}\n",
    "        for key in conn.keys():\n",
    "            for x in ['same', 'cross']:\n",
    "                conn[key][x] = []\n",
    "        \n",
    "        shared_features = ['blue', 'red', 'circle', 'triangle']\n",
    "        for f1 in shared_features:\n",
    "            for f2 in shared_features:\n",
    "                for sender, receiver in itertools.product(['sr_esoma', 'sr_pv'], repeat=2):\n",
    "                    mean_weight = np.mean(w_rec_eff[np.ix_(subcg_sr_idx['{}_{}'.format(f1, sender)], subcg_sr_idx['{}_{}'.format(f2, receiver)])])\n",
    "                    if f1==f2:\n",
    "                        conn[('shared_feature_{}'.format(sender), 'shared_feature_{}'.format(receiver))]['same'].append(mean_weight)\n",
    "                    elif f1!=f2 and shared_features.index(f1)//2 == shared_features.index(f2)//2:    # do not include for example f1=blue and f2=square\n",
    "                        conn[('shared_feature_{}'.format(sender), 'shared_feature_{}'.format(receiver))]['cross'].append(mean_weight)     \n",
    "                        \n",
    "        conn_bias_shared_feature_e_e = np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_esoma')]['same']) - np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_esoma')]['cross'])\n",
    "        conn_bias_shared_feature_e_pv = np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_pv')]['same']) - np.mean(conn[('shared_feature_sr_esoma', 'shared_feature_sr_pv')]['cross'])\n",
    "        conn_bias_shared_feature_pv_e = - (np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_esoma')]['cross']) - np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_esoma')]['same']))\n",
    "        conn_bias_shared_feature_pv_pv = - (np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_pv')]['cross']) - np.mean(conn[('shared_feature_sr_pv', 'shared_feature_sr_pv')]['same']))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        conn_bias_sr_all_models.append({'model': model_name, \n",
    "                                        'hp': hp_test,\n",
    "                                        'bias_ruleesoma_ruleesoma': conn_bias_rulee_rulee, \n",
    "                                        'bias_ruleesoma_rulepv': conn_bias_rulee_rulepv, \n",
    "                                        'bias_rulepv_ruleesoma': conn_bias_rulepv_rulee, \n",
    "                                        'bias_rulepv_rulepv': conn_bias_rulepv_rulepv,\n",
    "                                        'bias_respesoma_respesoma': conn_bias_respe_respe, \n",
    "                                        'bias_respesoma_resppv': conn_bias_respe_resppv, \n",
    "                                        'bias_resppv_respesoma': conn_bias_resppv_respe, \n",
    "                                        'bias_resppv_resppv': conn_bias_resppv_resppv,\n",
    "                                        'bias_ref_card_esoma_ref_card_esoma': conn_bias_ref_card_e_ref_card_e, \n",
    "                                        'bias_ref_card_esoma_ref_card_pv': conn_bias_ref_card_e_ref_card_pv, \n",
    "                                        'bias_ref_card_pv_ref_card_esoma': conn_bias_ref_card_pv_ref_card_e, \n",
    "                                        'bias_ref_card_pv_ref_card_pv': conn_bias_ref_card_pv_ref_card_pv,\n",
    "                                        'bias_shared_feature_esoma_esoma': conn_bias_shared_feature_e_e, \n",
    "                                        'bias_shared_feature_esoma_pv': conn_bias_shared_feature_e_pv, \n",
    "                                        'bias_shared_feature_pv_esoma': conn_bias_shared_feature_pv_e, \n",
    "                                        'bias_shared_feature_pv_pv': conn_bias_shared_feature_pv_pv,\n",
    "                                       })\n",
    "        print('biases: {}'.format(conn_bias_sr_all_models[-1][2:]))\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['divisive_2']:\n",
    "        continue\n",
    "    data = list(x.values())[2:6]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'rule E $\\rightarrow$ rule E', r'rule E $\\rightarrow$ rule PV', r'rule PV $\\rightarrow$ rule E', r'rule PV $\\rightarrow$ rule PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['divisive_2']:\n",
    "        continue\n",
    "    data = list(x.values())[6:10]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'resp E $\\rightarrow$ resp E', r'resp E $\\rightarrow$ resp PV', r'resp PV $\\rightarrow$ resp E', r'resp PV $\\rightarrow$ resp PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=[7,3])\n",
    "# fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "# fig.patch.set_facecolor('white')\n",
    "# for x in conn_bias_sr_all_models:\n",
    "#     if x['hp']['dend_nonlinearity'] not in ['divisive_2']:\n",
    "#         continue\n",
    "#     data = list(x.values())[10:14]\n",
    "#     if np.isnan(data).any():\n",
    "#         continue\n",
    "#     ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "# ax.set_xticks(np.arange(len(data)))\n",
    "# ax.set_xticklabels([r'ref card E $\\rightarrow$ ref card E', r'ref card E $\\rightarrow$ ref card PV', r'ref card PV $\\rightarrow$ ref card E', r'ref card PV $\\rightarrow$ ref card PV'], rotation=10)\n",
    "# ax.axhline(y=0, ls='--', color='k')\n",
    "# ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# # ax.set_ylim(-1,2)\n",
    "# ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "# make_pretty_axes(ax)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[7,3])\n",
    "fig.suptitle('Connectivity biases across all models', fontsize=20)\n",
    "fig.patch.set_facecolor('white')\n",
    "for x in conn_bias_sr_all_models:\n",
    "    if x['hp']['dend_nonlinearity'] not in ['divisive_2']:\n",
    "        continue\n",
    "    data = list(x.values())[14:18]\n",
    "    if np.isnan(data).any():\n",
    "        continue\n",
    "    ax.plot(data, marker='o', color='k', linewidth=2, markersize=10, alpha=0.5)\n",
    "ax.set_xticks(np.arange(len(data)))\n",
    "ax.set_xticklabels([r'shared feature E $\\rightarrow$ E', r'shared feature E $\\rightarrow$ PV', r'shared feature PV $\\rightarrow$ E', r'shared feature PV $\\rightarrow$ PV'], rotation=10)\n",
    "ax.axhline(y=0, ls='--', color='k')\n",
    "ax.set_xlim(-0.5, len(data)-0.5)\n",
    "# ax.set_ylim(-1,2)\n",
    "ax.set_ylabel('Connectivity bias', fontsize=20)\n",
    "make_pretty_axes(ax)\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
